{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM1qSBneh8WHd++I6IXqLhi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gillesretiere/langdeck/blob/novomaster/langdeck_pipe_2023_v2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "rImfLGHaFBhP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zxZ74yYaEuMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac5a1fd7-e0ba-41ce-f8f6-e32b695356a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyclean\n",
            "  Downloading pyclean-2.7.5-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m778.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyclean\n",
            "Successfully installed pyclean-2.7.5\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Collecting gspread\n",
            "  Downloading gspread-5.12.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m721.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from gspread) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from gspread) (1.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.12.0->gspread) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.12.0->gspread) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.12.0->gspread) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.12.0->gspread) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2023.7.22)\n",
            "Installing collected packages: gspread\n",
            "  Attempting uninstall: gspread\n",
            "    Found existing installation: gspread 3.4.2\n",
            "    Uninstalling gspread-3.4.2:\n",
            "      Successfully uninstalled gspread-3.4.2\n",
            "Successfully installed gspread-5.12.0\n",
            "Found existing installation: gspread-dataframe 3.3.1\n",
            "Uninstalling gspread-dataframe-3.3.1:\n",
            "  Successfully uninstalled gspread-dataframe-3.3.1\n",
            "Collecting gspread-dataframe\n",
            "  Downloading gspread_dataframe-3.3.1-py2.py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: gspread>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from gspread-dataframe) (5.12.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from gspread-dataframe) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from gspread-dataframe) (1.16.0)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from gspread>=3.0.0->gspread-dataframe) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from gspread>=3.0.0->gspread-dataframe) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->gspread-dataframe) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->gspread-dataframe) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->gspread-dataframe) (1.23.5)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.12.0->gspread>=3.0.0->gspread-dataframe) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.12.0->gspread>=3.0.0->gspread-dataframe) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.12.0->gspread>=3.0.0->gspread-dataframe) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread-dataframe) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread>=3.0.0->gspread-dataframe) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread-dataframe) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread-dataframe) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread-dataframe) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread-dataframe) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread-dataframe) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread-dataframe) (2023.7.22)\n",
            "Installing collected packages: gspread-dataframe\n",
            "Successfully installed gspread-dataframe-3.3.1\n",
            "Collecting gspread-formatting\n",
            "  Downloading gspread_formatting-1.1.2-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: gspread>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from gspread-formatting) (5.12.0)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from gspread>=3.0.0->gspread-formatting) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from gspread>=3.0.0->gspread-formatting) (1.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.12.0->gspread>=3.0.0->gspread-formatting) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.12.0->gspread>=3.0.0->gspread-formatting) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.12.0->gspread>=3.0.0->gspread-formatting) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.12.0->gspread>=3.0.0->gspread-formatting) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread-formatting) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread>=3.0.0->gspread-formatting) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread-formatting) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread-formatting) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread-formatting) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread-formatting) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread-formatting) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread-formatting) (2023.7.22)\n",
            "Installing collected packages: gspread-formatting\n",
            "Successfully installed gspread-formatting-1.1.2\n",
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/langdeck\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n",
            "Collecting airtable-python-wrapper\n",
            "  Downloading airtable_python_wrapper-0.15.3-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.10/dist-packages (from airtable-python-wrapper) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2->airtable-python-wrapper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2->airtable-python-wrapper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2->airtable-python-wrapper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2->airtable-python-wrapper) (2023.7.22)\n",
            "Installing collected packages: airtable-python-wrapper\n",
            "Successfully installed airtable-python-wrapper-0.15.3\n",
            "Collecting deep-translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m991.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (4.11.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2023.7.22)\n",
            "Installing collected packages: deep-translator\n",
            "Successfully installed deep-translator-1.11.4\n",
            "Collecting deepl\n",
            "  Downloading deepl-1.16.1-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from deepl) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->deepl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->deepl) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->deepl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->deepl) (2023.7.22)\n",
            "Installing collected packages: deepl\n",
            "Successfully installed deepl-1.16.1\n",
            "Collecting larousse-api-sunbro\n",
            "  Downloading larousse_api_sunbro-0.0.5-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from larousse-api-sunbro) (2.31.0)\n",
            "Collecting bs4>=0.0.1 (from larousse-api-sunbro)\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4>=0.0.1->larousse-api-sunbro) (4.11.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->larousse-api-sunbro) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->larousse-api-sunbro) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->larousse-api-sunbro) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->larousse-api-sunbro) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4>=0.0.1->larousse-api-sunbro) (2.5)\n",
            "Building wheels for collected packages: bs4\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=1f49bfd6efd8ca7f88fa7dd02d6d7d9161f4310d0ab8eb295ecc24db3321e7e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "Successfully built bs4\n",
            "Installing collected packages: bs4, larousse-api-sunbro\n",
            "Successfully installed bs4-0.0.1 larousse-api-sunbro-0.0.5\n",
            "Collecting git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git\n",
            "  Cloning https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git to /tmp/pip-req-build-o15kb3j2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git /tmp/pip-req-build-o15kb3j2\n",
            "  Resolved https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git to commit bc0ebd0135a6cc78f48ddf184069b4c0b9c017d8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: FrenchLefffLemmatizer\n",
            "  Building wheel for FrenchLefffLemmatizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for FrenchLefffLemmatizer: filename=FrenchLefffLemmatizer-0.3-py3-none-any.whl size=3533513 sha256=6990b71f2b0297a27139bdd5424f0acaba061a5e106f1c91bd49cfe49ca1561d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0u5tf6rw/wheels/99/54/81/553bffdc8e0781c925f9a26606894935adb29b56175a9a358b\n",
            "Successfully built FrenchLefffLemmatizer\n",
            "Installing collected packages: FrenchLefffLemmatizer\n",
            "Successfully installed FrenchLefffLemmatizer-0.3\n",
            "Collecting gtts\n",
            "  Downloading gTTS-2.4.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2023.7.22)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.4.0\n",
            "Collecting cloudinary\n",
            "  Downloading cloudinary-1.36.0.tar.gz (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from cloudinary) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.10/dist-packages (from cloudinary) (2.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from cloudinary) (2023.7.22)\n",
            "Building wheels for collected packages: cloudinary\n",
            "  Building wheel for cloudinary (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cloudinary: filename=cloudinary-1.36.0-py3-none-any.whl size=138826 sha256=6759dba383fcc137a6702ba18592d89a944cb5fe86c8c9ac9441469039739935\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/a8/27/11b1a23f6bd923d99089038af583a1f84c734dee7ab87ff263\n",
            "Successfully built cloudinary\n",
            "Installing collected packages: cloudinary\n",
            "Successfully installed cloudinary-1.36.0\n",
            "/content/drive/MyDrive/langdeck\n",
            "Cleaning directory .\n",
            "Total 2 files, 1 directories removed.\n",
            "Version : 20231011-180000\n",
            "/content/drive/MyDrive/langdeck\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf8 -*-\n",
        "import pandas as pd\n",
        "pd.set_option(\"display.width\",1000)\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "import numpy as np\n",
        "import requests\n",
        "import json\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "import datetime\n",
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "import ast\n",
        "\n",
        "!pip3 install pyclean\n",
        "\n",
        "# Gspread  API for Google sheets\n",
        "!pip install gspread --upgrade\n",
        "# fix here => https://stackoverflow.com/questions/71347973/modulenotfounderror-no-module-named-gspread-models\n",
        "!pip uninstall -y gspread-dataframe\n",
        "!pip install gspread-dataframe\n",
        "!pip install gspread-formatting\n",
        "\n",
        "#==== Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/langdeck/\n",
        "from google.colab import files\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "#====== Google Credentials ================\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# fix here => https://github.com/burnash/gspread/issues/1014\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "# python .env see -> https://saurabh-kumar.com/python-dotenv/\n",
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv\n",
        "from dotenv import dotenv_values\n",
        "load_dotenv()\n",
        "dotenv_config = dotenv_values(\".env\")\n",
        "app_path = dotenv_config[\"APP_PATH\"]\n",
        "\n",
        "#====== GSpread is a Python API for Google Sheets.================\n",
        "import gspread\n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "from gspread_formatting import *\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "#====== Airtable ================\n",
        "!pip install airtable-python-wrapper\n",
        "from airtable import Airtable\n",
        "\n",
        "#====== Deep Translate ================\n",
        "!pip install -U deep-translator\n",
        "!pip install --upgrade deepl\n",
        "\n",
        "#====== Dictionaries ================\n",
        "# larousse API\n",
        "!pip install larousse-api-sunbro\n",
        "\n",
        "#====== Lemmatizers ================\n",
        "# https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer\n",
        "!pip install git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git\n",
        "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
        "lemmatizer = FrenchLefffLemmatizer()\n",
        "\n",
        "#====== Text To Speech\n",
        "# about quotas : https://stackoverflow.com/questions/65980562/gtts-tts-gttserror-429-too-many-requests-from-tts-api-probable-cause-unknow\n",
        "import os\n",
        "!pip install gtts --upgrade\n",
        "from gtts import gTTS\n",
        "\n",
        "# CDN Cloudinary for upload\n",
        "!pip3 install cloudinary\n",
        "import cloudinary\n",
        "import cloudinary.uploader\n",
        "import cloudinary.api\n",
        "from cloudinary.uploader import upload\n",
        "from cloudinary.utils import cloudinary_url\n",
        "\n",
        "!export PYTHONIOENCODING=utf8\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%cd /content/drive/MyDrive/langdeck/\n",
        "!pyclean .\n",
        "import sys, os\n",
        "sys.path.append('/content/drive/MyDrive/langdeck/py_modules')\n",
        "import py_modules\n",
        "py_modules.test()\n",
        "\n",
        "# .env\n",
        "from dotenv import load_dotenv\n",
        "from dotenv import dotenv_values\n",
        "%cd /content/drive/MyDrive/langdeck/\n",
        "load_dotenv()\n",
        "dotenv_config = dotenv_values(\".env\")\n",
        "\n",
        "# Config CDN\n",
        "cloudinary.config(\n",
        "  cloud_name = dotenv_config[\"CLOUDINARY_CLOUD_NAME\"],\n",
        "  api_key = dotenv_config[\"CLOUDINARY_API_KEY\"],\n",
        "  api_secret = dotenv_config[\"CLOUDINARY_API_SECRET\"],\n",
        "  secure = True\n",
        ")\n",
        "\n",
        "load_dotenv()\n",
        "dotenv_config = dotenv_values(\".env\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test cnx integration DB\n",
        "Ici on teste la cnx avec la base d'intégration qui est une table GSHEET"
      ],
      "metadata": {
        "id": "TPyXGR6PFJ5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def deep_translator_translate (input, source_language, target_language):\n",
        "  from deep_translator import GoogleTranslator\n",
        "  return GoogleTranslator(source=source_language, target=target_language).translate(input)"
      ],
      "metadata": {
        "id": "8jBdDY1Yu8Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_lgdk_intgr = dotenv_config[\"DB_LGDK_INTGR\"]\n",
        "#--- integration database\n",
        "sheet = db_lgdk_intgr\n",
        "wb_intgr  = gc.open_by_url(sheet)\n",
        "#--- Liste des codes ISO639-3\n",
        "df_lang_alpha3 = py_modules.load_df_from_gsheet (wb_intgr, \"ref_iso-639-3\")\n",
        "#--- Liste des langues (issues d'un Corpus)\n",
        "df_lang_corpus = py_modules.load_df_from_gsheet (wb_intgr, \"ref_lang_corpus\")\n",
        "# df_lang_corpus.head()"
      ],
      "metadata": {
        "id": "Rj400JYiFNdl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test cnx DSGN DB\n",
        "Ici on teste la cnx avec la base de DESIGN qui est une table Airtable\n",
        "##### doc : https://airtable-python-wrapper.readthedocs.io/en/airtable-python-wrapper/index.html\n"
      ],
      "metadata": {
        "id": "YTEefXsNGM_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#---- Base Airtable 2023\n",
        "api_key_airtable = dotenv_config[\"AIRTABLE_PIPE23_API_KEY\"]\n",
        "headers = {\"Authorization\": \"Bearer \" + api_key_airtable,\"Content-Type\" : \"application/json\"}\n",
        "base_id = dotenv_config[\"AIRTABLE_PIPE23_BASE_ID\"]\n",
        "table_name = dotenv_config[\"AIRTABLE_PIPE23_TBL_NAME\"]\n",
        "airtable = Airtable(base_id, table_name, api_key_airtable)\n",
        "active_filter = \"{Status}='Done'\""
      ],
      "metadata": {
        "id": "UXCaoxOiGEmL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langues"
      ],
      "metadata": {
        "id": "Y33GmC59GXP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tbd_languages = Airtable(base_id, \"languages\", api_key_airtable)\n",
        "lang_filter = \"{lang_is_available}='TRUE'\"\n",
        "vw_lang_grid = tbd_languages.get_all(\n",
        "    view='view_grid',\n",
        "    sort=['lang_id','lang_is_available'],\n",
        "    formula=lang_filter,\n",
        "    )"
      ],
      "metadata": {
        "id": "uLfP0dH-GRrZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thèmes"
      ],
      "metadata": {
        "id": "0dbBzlD1Gh-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intégration"
      ],
      "metadata": {
        "id": "weYk1sXtGlfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tbd_themes = Airtable(base_id, \"themes\", api_key_airtable)\n",
        "vw_themes_grid = tbd_themes.get_all(\n",
        "    view='view_grid',\n",
        "    sort=['theme_name'],\n",
        "    formula=active_filter,\n",
        "    )\n",
        "\n",
        "#=======================================================\n",
        "# Transfo en dataframe\n",
        "#=======================================================\n",
        "df_themes = pd.DataFrame.from_records((r['fields'] for r in vw_themes_grid))\n",
        "df_themes = df_themes[[\"theme_rec_id\",\n",
        "                 \"theme_name\",\n",
        "                 \"theme_desc\",\n",
        "                 \"stories\",\n",
        "                 ]]\n",
        "\n",
        "\n",
        "#=======================================================\n",
        "# Ajout des langues en colonnes\n",
        "#=======================================================\n",
        "df_languages = pd.DataFrame.from_records((r['fields'] for r in vw_lang_grid))\n",
        "df_languages[\"lang_is_tts\"] = df_languages[\"lang_is_tts\"].map(lambda x:True if x==\"TRUE\" else False)\n",
        "df_languages[\"lang_is_available\"] = df_languages[\"lang_is_available\"].map(lambda x:True if x==\"TRUE\" else False)\n",
        "py_modules.save_df_to_gsheet (wb_intgr, \"tbl_languages\", df_languages)\n",
        "\n",
        "# on transpose chaque trigramme de langue en une colonne supplémentaire (values n'a pas d'importance car on vide la table ensuite)\n",
        "df_t = df_languages.pivot(columns='lang_id', values='lang_alpha3')\n",
        "df_t = df_t[0:0]\n",
        "df_themes = pd.concat([df_themes, df_t.reindex(df_themes.index)], axis=1)\n",
        "#=======================================================\n",
        "#---- Transposition des colonnes de langues en lignes\n",
        "#=======================================================\n",
        "df_w_temp = pd.melt(df_themes,\n",
        "        id_vars=[\"theme_rec_id\",\n",
        "                 \"theme_name\",\n",
        "                 \"theme_desc\",\n",
        "                 \"stories\"],\n",
        "        var_name=\"theme_language\",\n",
        "        value_name=\"translation\")\n",
        "# hash incl. language iso3\n",
        "df_w_temp[\"theme_translation_id\"] = df_w_temp[['theme_rec_id', 'theme_language']].apply(\n",
        "    lambda x: \"{}-{}\".format(x[0],x[1]),\n",
        "    axis=1)\n",
        "# left join to include translations\n",
        "df_w_temp.drop(columns=[\"translation\",], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "#=======================================================\n",
        "#---- Merge avec les traductions existantes\n",
        "#=======================================================\n",
        "df_tbl_themes = py_modules.load_df_from_gsheet (wb_intgr, \"tbl_themes\")\n",
        "df_w_tr = pd.merge(\n",
        "    df_w_temp,\n",
        "    df_tbl_themes[[\"theme_translation_id\",\n",
        "                  \"theme_translation\",\n",
        "                  \"theme_translation_status\",\n",
        "                  \"theme_audio\",\n",
        "                  \"theme_audio_url\",\n",
        "                  \"theme_audio_url_fr\"]],\n",
        "    on=\"theme_translation_id\",\n",
        "    how=\"left\")"
      ],
      "metadata": {
        "id": "i8R1ZI29GWni"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traduction"
      ],
      "metadata": {
        "id": "BABaQl-JGtyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_w_tr[\"theme_translation\"] = df_w_tr[\"theme_translation\"].map(\n",
        "    lambda x: np.nan if isinstance(x, str) and (x.isspace() or not x) else x)\n",
        "df_w_tr[\"theme_translation_status\"] = df_w_tr[\"theme_translation_status\"].map(\n",
        "    lambda x: np.nan if isinstance(x, str) and (x.isspace() or not x) else x)\n",
        "# translate if necessary # status == NaN OR START\n",
        "df_w_tr[[\"theme_translation\",\"theme_translation_status\"]] = df_w_tr[[\"theme_translation\",\n",
        "                                                                   \"theme_name\",\n",
        "                                                                   \"theme_language\",\n",
        "                                                                   \"theme_translation_status\"]].apply(\n",
        "    lambda x:py_modules.word_translate_update_status(\n",
        "        x[1],\n",
        "        \"fre\",\n",
        "        x[2],\n",
        "        x[3],\n",
        "        df_languages)\n",
        "    if (pd.isna(x[0]) or pd.isna(x[3]) or x[3].lower()==\"update\")\n",
        "    else (x[0],x[3]),\n",
        "    axis=1,\n",
        "    result_type=\"expand\"\n",
        "    )\n",
        "\n",
        "# emplacement du fichier audio correspondant au mot traduit\n",
        "df_w_tr[\"theme_audio\"] = df_w_tr[[\"theme_translation_id\",\"theme_language\"]].apply(\n",
        "    lambda x:\"assets/audio/ai/\"+x[1]+\"/\"+str(x[0])+\".mp3\",\n",
        "    axis=1)"
      ],
      "metadata": {
        "id": "Bn97TptAHLH7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text To Speech"
      ],
      "metadata": {
        "id": "srDwHNmMG2mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check language directories\n",
        "audio_path = \"/content/drive/MyDrive/langdeck/assets/audio/ai/\"\n",
        "df_languages[\"lang_id\"].map(lambda x:py_modules.create_gdrive_folder(audio_path, x))\n",
        "# filtre sur les langues disponibles pour TTS (subset)\n",
        "\n",
        "vk_tts = df_languages.loc[df_languages[\"lang_is_tts\"]][\"lang_id\"].to_list()\n",
        "df_tts = df_w_tr.loc[df_w_tr[\"theme_language\"].isin(vk_tts)]\n",
        "# Appel TTS sur le subset (ex) : text2speech(\"Diet\", \"et\", audio_path +\"est\" + \"/\" + \"recIFmq8UmSGnpw0v-est.mp3\", False)\n",
        "df_tts[[\"theme_translation\",\"theme_language\",\"theme_audio\",\"theme_translation_status\"]].apply(\n",
        "    lambda x:py_modules.text2speech(\n",
        "    x[0],\n",
        "    df_languages.loc[df_languages[\"lang_id\"]==x[1].lower()][\"lang_alpha2\"].values.item(),\n",
        "    audio_path + x[1] + \"/\" + x[2].split(\"/\")[-1],\n",
        "    False)\n",
        "if py_modules.is_audio(audio_path + x[1] + \"/\", x[2].split(\"/\")[-1])==False\n",
        "or x[3].lower()==\"update\"\n",
        "else None,\n",
        "    axis=1)\n",
        "\n",
        "# replace spaces or empty string by Nan\n",
        "df_tts['theme_audio_url'] = df_tts['theme_audio_url'].map(\n",
        "    lambda x: np.nan\n",
        "    if isinstance(x, str) and (x.isspace() or not x)\n",
        "    else x)\n",
        "\n",
        "#=======================================================\n",
        "# UPLOAD TO CLOUDINARY\n",
        "#=======================================================\n",
        "\n",
        "# upload only if audio_public_url equals NaN (if url exists, file has yet been uploaded)\n",
        "#df_tts.loc[pd.isna(df_tts[\"audio_public_url\"])]\n",
        "df_tts[\"theme_audio_url\"] = df_tts[[\"theme_language\",\"theme_audio\",\"theme_audio_url\",\"theme_translation_status\"]].apply(\n",
        "    lambda x: py_modules.upload_to_cdn(\n",
        "    cloudinary,\n",
        "    x[0],\n",
        "    audio_path + x[0]+\"/\",\n",
        "    x[1].split(\"/\")[-1],\n",
        "    x[3])\n",
        "    if pd.isna(x[2]) or x[3].lower() == \"update\"\n",
        "    else x[2],\n",
        "    axis=1)\n",
        "\n",
        "# cette fonction donne pour le mot l'url de la version en français\n",
        "df_tts[\"theme_audio_url_fr\"] = df_tts[\"theme_rec_id\"].map(\n",
        "    lambda x:py_modules.theme_get_audio_url_fr(x, df_tts))"
      ],
      "metadata": {
        "id": "Pfe6ApzCG1HG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dc8f622-9f77-44f8-f586-2f95ea8cf3aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/langdeck/assets/audio/ai/dut\n",
            "/content/drive/MyDrive/langdeck/assets/audio/ai/eng\n",
            "/content/drive/MyDrive/langdeck/assets/audio/ai/fre\n",
            "/content/drive/MyDrive/langdeck/assets/audio/ai/ger\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "py_modules.save_df_to_gsheet (wb_intgr, \"tbl_themes\", df_tts)"
      ],
      "metadata": {
        "id": "8aHebRE9HR-Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stories"
      ],
      "metadata": {
        "id": "ma9KpyFNHpfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intégration"
      ],
      "metadata": {
        "id": "jJSje_nNIAys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tbd_stories = Airtable(base_id, \"stories\", api_key_airtable)\n",
        "vw_stories_grid = tbd_stories.get_all(\n",
        "    view='view_grid',\n",
        "    sort=['story_name','story_level'],\n",
        "    formula=active_filter,\n",
        "    )\n",
        "#=======================================================\n",
        "# Transfo en dataframe\n",
        "#=======================================================\n",
        "df_stories = pd.DataFrame.from_records((r['fields'] for r in vw_stories_grid))\n",
        "df_stories.rename(columns={'story_theme': 'story_theme_rec_id'}, inplace=True)\n",
        "df_stories[\"story_theme\"] = df_stories[\"story_theme_rec_id\"].map(\n",
        "    lambda x:py_modules.get_airtable_column_by_id(tbd_themes, x, \"theme_name\"),\n",
        "    na_action=\"ignore\"\n",
        ")\n",
        "vk_col_stories = [\"story_rec_id\",\n",
        "                 \"story_name\",\n",
        "                 \"story_episode\",\n",
        "                 \"story_level\",\n",
        "                 \"story_theme\",\n",
        "                 \"story_illustration\",\n",
        "                 \"paragraphs\",\n",
        "                 \"story_desc\",\n",
        "                 ]\n",
        "df_stories = df_stories[vk_col_stories]\n",
        "#=======================================================\n",
        "# Ajout des langues en colonnes\n",
        "#=======================================================\n",
        "# df_languages = pd.DataFrame.from_records((r['fields'] for r in vw_lang_grid))\n",
        "df_languages = py_modules.load_df_from_gsheet (wb_intgr, \"tbl_languages\")\n",
        "df_languages[\"lang_is_tts\"] = df_languages[\"lang_is_tts\"].map(lambda x:True if x==\"TRUE\" else False)\n",
        "df_languages[\"lang_is_available\"] = df_languages[\"lang_is_available\"].map(lambda x:True if x==\"TRUE\" else False)\n",
        "\n",
        "# on transpose chaque trigramme de langue en une colonne supplémentaire (values n'a pas d'importance car on vide la table ensuite)\n",
        "df_t = df_languages.pivot(columns='lang_id', values='lang_alpha3')\n",
        "df_t = df_t[0:0]\n",
        "df_stories = pd.concat([df_stories, df_t.reindex(df_stories.index)], axis=1)\n",
        "#=======================================================\n",
        "#---- Transposition des colonnes de langues en lignes\n",
        "#=======================================================\n",
        "df_w_temp = pd.melt(df_stories,\n",
        "        id_vars=vk_col_stories,\n",
        "        var_name=\"story_language\",\n",
        "        value_name=\"translation\")\n",
        "# hash incl. language iso3\n",
        "df_w_temp[\"story_translation_id\"] = df_w_temp[['story_rec_id', 'story_language']].apply(\n",
        "    lambda x: \"{}-{}\".format(x[0],x[1]),\n",
        "    axis=1)\n",
        "# left join to include translations\n",
        "df_w_temp.drop(columns=[\"translation\",], axis=1, inplace=True)\n",
        "#=======================================================\n",
        "#---- Merge avec les traductions existantes\n",
        "#=======================================================\n",
        "df_tbl_stories = py_modules.load_df_from_gsheet (wb_intgr, \"tbl_stories\")\n",
        "df_w_tr = pd.merge(\n",
        "    df_w_temp,\n",
        "    df_tbl_stories[[\"story_translation_id\",\n",
        "                  \"story_translation\",\n",
        "                  \"story_translation_status\",\n",
        "                  \"story_audio\",\n",
        "                  \"story_audio_url\",\n",
        "                  \"story_audio_url_fr\",\n",
        "                  \"story_desc_translation\",\n",
        "                  ]],\n",
        "    on=\"story_translation_id\",\n",
        "    how=\"left\")"
      ],
      "metadata": {
        "id": "l3on7mFxILh6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traduction"
      ],
      "metadata": {
        "id": "41MEl4G_IDud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_w_tr[\"story_translation\"] = df_w_tr[\"story_translation\"].map(\n",
        "    lambda x: np.nan if isinstance(x, str) and (x.isspace() or not x) else x)\n",
        "df_w_tr[\"story_translation_status\"] = df_w_tr[\"story_translation_status\"].map(\n",
        "    lambda x: np.nan if isinstance(x, str) and (x.isspace() or not x) else x)\n",
        "# translate if necessary # status == NaN OR START\n",
        "df_w_tr[[\"story_translation\",\"story_translation_status\"]] = df_w_tr[[\"story_translation\",\n",
        "                                                                   \"story_name\",\n",
        "                                                                   \"story_language\",\n",
        "                                                                   \"story_translation_status\"]].apply(\n",
        "    lambda x:py_modules.word_translate_update_status(\n",
        "        x[1],\n",
        "        \"fre\",\n",
        "        x[2],\n",
        "        x[3],\n",
        "        df_languages)\n",
        "    if (pd.isna(x[0]) or pd.isna(x[3]) or x[3].lower()==\"update\")\n",
        "    else (x[0],x[3]),\n",
        "    axis=1,\n",
        "    result_type=\"expand\"\n",
        "    )\n",
        "\n",
        "# emplacement du fichier audio correspondant au mot traduit\n",
        "df_w_tr[\"story_audio\"] = df_w_tr[[\"story_translation_id\",\"story_language\"]].apply(\n",
        "    lambda x:\"assets/audio/ai/\"+x[1]+\"/\"+str(x[0])+\".mp3\",\n",
        "    axis=1)"
      ],
      "metadata": {
        "id": "bQPyVjV1IruU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text To Speech"
      ],
      "metadata": {
        "id": "ihWfQfBIIHjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check language directories\n",
        "audio_path = \"/content/drive/MyDrive/langdeck/assets/audio/ai/\"\n",
        "df_languages[\"lang_id\"].map(lambda x:py_modules.create_gdrive_folder(audio_path, x))\n",
        "# filtre sur les langues disponibles pour TTS (subset)\n",
        "\n",
        "vk_tts = df_languages.loc[df_languages[\"lang_is_tts\"]][\"lang_id\"].to_list()\n",
        "df_tts = df_w_tr.loc[df_w_tr[\"story_language\"].isin(vk_tts)]\n",
        "# Appel TTS sur le subset (ex) : text2speech(\"Diet\", \"et\", audio_path +\"est\" + \"/\" + \"recIFmq8UmSGnpw0v-est.mp3\", False)\n",
        "df_tts[[\"story_translation\",\"story_language\",\"story_audio\",\"story_translation_status\"]].apply(\n",
        "    lambda x:py_modules.text2speech(\n",
        "    x[0],\n",
        "    df_languages.loc[df_languages[\"lang_id\"]==x[1].lower()][\"lang_alpha2\"].values.item(),\n",
        "    audio_path + x[1] + \"/\" + x[2].split(\"/\")[-1],\n",
        "    False)\n",
        "if py_modules.is_audio(audio_path + x[1] + \"/\", x[2].split(\"/\")[-1])==False\n",
        "or x[3].lower()==\"update\"\n",
        "else None,\n",
        "    axis=1)\n",
        "\n",
        "# replace spaces or empty string by Nan\n",
        "df_tts['story_audio_url'] = df_tts['story_audio_url'].map(\n",
        "    lambda x: np.nan\n",
        "    if isinstance(x, str) and (x.isspace() or not x)\n",
        "    else x)\n",
        "\n",
        "#=======================================================\n",
        "# UPLOAD TO CLOUDINARY\n",
        "#=======================================================\n",
        "\n",
        "# upload only if audio_public_url equals NaN (if url exists, file has yet been uploaded)\n",
        "#df_tts.loc[pd.isna(df_tts[\"audio_public_url\"])]\n",
        "df_tts[\"story_audio_url\"] = df_tts[[\"story_language\",\"story_audio\",\"story_audio_url\",\"story_translation_status\"]].apply(\n",
        "    lambda x: py_modules.upload_to_cdn(\n",
        "    cloudinary,\n",
        "    x[0],\n",
        "    audio_path + x[0]+\"/\",\n",
        "    x[1].split(\"/\")[-1],\n",
        "    x[3])\n",
        "    if pd.isna(x[2]) or x[3].lower() == \"update\"\n",
        "    else x[2],\n",
        "    axis=1)\n",
        "\n",
        "# cette fonction donne pour le mot l'url de la version en français\n",
        "df_tts[\"story_audio_url_fr\"] = df_tts[\"story_rec_id\"].map(\n",
        "    lambda x:py_modules.story_get_audio_url_fr(x, df_tts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlZ_WlUpHtW6",
        "outputId": "488c4cc7-2d69-4c23-d24c-a16b4d87d54d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/langdeck/assets/audio/ai/dut\n",
            "/content/drive/MyDrive/langdeck/assets/audio/ai/eng\n",
            "/content/drive/MyDrive/langdeck/assets/audio/ai/fre\n",
            "/content/drive/MyDrive/langdeck/assets/audio/ai/ger\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translation of story description"
      ],
      "metadata": {
        "id": "DIMKEZaUJbaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# translate if necessary # status == NaN OR START\n",
        "df_tts[\"story_desc_translation\"] = df_tts[\"story_desc_translation\"].map(\n",
        "    lambda x: np.nan if isinstance(x, str) and (x.isspace() or not x) else x)\n",
        "df_tts[[\"story_desc_translation\",\"story_desc_translation_status\"]] = df_tts[\n",
        "    [\"story_desc_translation\",\n",
        "     \"story_desc\",\n",
        "     \"story_language\",\n",
        "     \"story_translation_status\"]].apply(\n",
        "    lambda x:py_modules.word_translate_update_status(\n",
        "        x[1],\n",
        "        \"fre\",\n",
        "        x[2],\n",
        "        x[3],\n",
        "        df_languages)\n",
        "    if ((pd.isna(x[0]) and not pd.isna(x[1])) or x[3]=='Start')\n",
        "    else (x[0],x[3]),\n",
        "    axis=1,\n",
        "    result_type=\"expand\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "4I2EsTHJJjyI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "py_modules.save_df_to_gsheet (wb_intgr, \"tbl_stories\", df_tts)"
      ],
      "metadata": {
        "id": "77Rg64W6IwYa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Words"
      ],
      "metadata": {
        "id": "06x6xhqSJ1jl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tbd_words = Airtable(base_id, \"words\", api_key_airtable)\n",
        "vw_words_grid = tbd_words.get_all(\n",
        "    view='view_grid',\n",
        "    sort=['word','word_type'],\n",
        "    formula=active_filter,\n",
        "    )"
      ],
      "metadata": {
        "id": "brt7V2wc8Ftj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intégration"
      ],
      "metadata": {
        "id": "-6AhCBt9J_86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#=======================================================\n",
        "# Transfo en dataframe\n",
        "#=======================================================\n",
        "df_words = pd.DataFrame.from_records((r['fields'] for r in vw_words_grid))\n",
        "# on ne garde que les colonnes utiles\n",
        "df_words = df_words[[\"word_rec_id\",\n",
        "                     \"word\",\n",
        "                     \"word_type\",\n",
        "                     \"word_lemmas\",\n",
        "                     \"word_notes\",\n",
        "                     \"word_nutri_notes\",\n",
        "                     \"word_notes_status\",\n",
        "                     \"word_nutri_notes_status\",\n",
        "                     ]]\n",
        "# Capitalisation\n",
        "df_words[\"word\"]=df_words[\"word\"].map(lambda x:x[:1].upper() + x[1:])\n",
        "# on convertit les rec_id en valeur litérale\n",
        "df_words.rename(columns={'word_lemmas': 'word_lemmas_rec_id'}, inplace=True)\n",
        "# on convertit les rec_id en valeur litérale\n",
        "df_words[\"word_lemmas\"] = df_words[\"word_lemmas_rec_id\"].map(\n",
        "    lambda x:py_modules.get_word_lemma_by_id(tbd_words, x),\n",
        "    na_action=\"ignore\")\n",
        "\n",
        "#=======================================================\n",
        "# Ajout des langues en colonnes\n",
        "#=======================================================\n",
        "df_languages = pd.DataFrame.from_records((r['fields'] for r in vw_lang_grid))\n",
        "# on transpose chaque trigramme de langue en une colonne supplémentaire (values n'a pas d'importance car on vide la table ensuite)\n",
        "df_t = df_languages.pivot(columns='lang_id', values='lang_alpha3')\n",
        "df_t = df_t[0:0]\n",
        "df_words = pd.concat([df_words, df_t.reindex(df_words.index)], axis=1)\n",
        "\n",
        "#=======================================================\n",
        "#---- Transposition des colonnes de langues en lignes\n",
        "#=======================================================\n",
        "df_w_temp = pd.melt(df_words,\n",
        "        id_vars=[\"word_rec_id\",\n",
        "                 \"word\",\n",
        "                 \"word_type\",\n",
        "                 \"word_lemmas\",\n",
        "                 \"word_lemmas_rec_id\",\n",
        "                 \"word_notes\",\n",
        "                 \"word_nutri_notes\",\n",
        "                 \"word_notes_status\",\n",
        "                 \"word_nutri_notes_status\",\n",
        "                 ],\n",
        "        var_name=\"word_language\",\n",
        "        value_name=\"translation\")\n",
        "# hash incl. language iso3\n",
        "df_w_temp[\"word_translation_id\"] = df_w_temp[['word_rec_id', 'word_language']].apply(\n",
        "    lambda x: \"{}-{}\".format(x[0],x[1]),\n",
        "    axis=1)\n",
        "# left join to include translations\n",
        "df_w_temp.drop(columns=[\"translation\",], axis=1, inplace=True)\n",
        "#=======================================================\n",
        "#---- Merge avec les traductions existantes\n",
        "#=======================================================\n",
        "df_tbl_words = py_modules.load_df_from_gsheet (wb_intgr, \"tbl_words\")\n",
        "df_w_tr = pd.merge(\n",
        "    df_w_temp,\n",
        "    df_tbl_words[[\"word_translation_id\",\n",
        "                  \"word_translation\",\n",
        "                  \"word_translation_status\",\n",
        "                  \"word_audio\",\n",
        "                  \"word_audio_url\",\n",
        "                  \"word_audio_url_fr\",\n",
        "                  \"word_notes_translation\",\n",
        "                  \"word_notes_translation_status\",\n",
        "                  \"word_nutri_notes_translation\",\n",
        "                  \"word_nutri_notes_translation_status\",\n",
        "                  ]],\n",
        "    on=\"word_translation_id\",\n",
        "    how=\"left\")\n"
      ],
      "metadata": {
        "id": "EfyIea4P5PSn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traduction"
      ],
      "metadata": {
        "id": "8IrjabixKCzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_w_tr[\"word_translation\"] = df_w_tr[\"word_translation\"].map(\n",
        "    lambda x: np.nan if isinstance(x, str) and (x.isspace() or not x) else x)\n",
        "df_w_tr[\"word_translation_status\"] = df_w_tr[\"word_translation_status\"].map(\n",
        "    lambda x: np.nan if isinstance(x, str) and (x.isspace() or not x) else x)\n",
        "# il faut forcer la maj car les lemmes ont peut-être changé => on recrée la colonne from scratch\n",
        "df_w_tr[\"word_lemmas_tr_rec_id\"]=df_w_tr[[\"word_lemmas_rec_id\",\"word_language\"]].apply(\n",
        "    lambda x:py_modules.f_word_lemmas_tr_rec_id(x[0],x[1]) if type(x[0])==list else np.nan,\n",
        "    axis=1)\n",
        "# translate if necessary # status == NaN OR START\n",
        "df_w_tr[[\"word_translation\",\"word_translation_status\"]] = df_w_tr[[\"word_translation\",\n",
        "                                                                   \"word\",\n",
        "                                                                   \"word_language\",\n",
        "                                                                   \"word_translation_status\"]].apply(\n",
        "    lambda x:py_modules.word_translate_update_status(\n",
        "        x[1],\n",
        "        \"fre\",\n",
        "        x[2],\n",
        "        x[3],\n",
        "        df_languages)\n",
        "    if (pd.isna(x[0]) or pd.isna(x[3]) or x[3].lower()==\"update\")\n",
        "    else (x[0],x[3]),\n",
        "    axis=1,\n",
        "    result_type=\"expand\"\n",
        "    )\n",
        "\n",
        "# on convertit les rec_id en valeur litérale\n",
        "df_w_tr[\"word_lemmas_tr\"] = df_w_tr[\"word_lemmas_tr_rec_id\"].map(\n",
        "    lambda x:py_modules.f_word_lemmas_tr(x, df_w_tr),\n",
        "    na_action=\"ignore\")\n",
        "\n",
        "# emplacement du fichier audio correspondant au mot traduit\n",
        "df_w_tr[\"word_audio\"] = df_w_tr[[\"word_translation_id\",\"word_language\"]].apply(\n",
        "    lambda x:\"assets/audio/ai/\"+x[1]+\"/\"+str(x[0])+\".mp3\",\n",
        "    axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "SyOLWtQLJ7Jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de329e12-d0f6-415c-aedb-64053bcb682c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated Super... from fre to nl >>> Fantastisc...\n",
            "Translated Super... from fre to en >>> Great...\n",
            "Translated Super... from fre to fr >>> Super...\n",
            "Translated Super... from fre to de >>> Großartig...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notes and Nutri notes"
      ],
      "metadata": {
        "id": "k2pSgOaXm26i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_w_tr[\"word_notes_translation\"] = df_w_tr[\"word_notes_translation\"].map(\n",
        "    lambda x: np.nan if isinstance(x, str) and (x.isspace() or not x) else x)\n",
        "df_w_tr[\"word_notes_translation_status\"] = df_w_tr[\"word_notes_translation_status\"].map(\n",
        "    lambda x: np.nan if isinstance(x, str) and (x.isspace() or not x) else x)"
      ],
      "metadata": {
        "id": "2BLCxpTskb4L"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# notes et nutri-notes\n",
        "# translate if necessary # status == NaN OR START\n",
        "df_w_tr[[\"word_notes_translation\",\"word_notes_translation_status\"]] = df_w_tr[\n",
        "    [\"word_notes_translation\",\n",
        "     \"word_notes\",\n",
        "     \"word_language\",\n",
        "     \"word_notes_translation_status\"]].apply(\n",
        "    lambda x:py_modules.word_translate_update_status(\n",
        "        x[1],\n",
        "        \"fre\",\n",
        "        x[2],\n",
        "        x[3],\n",
        "        df_languages)\n",
        "    if ((pd.isna(x[0]) and not pd.isna(x[1])) or x[3]=='update')\n",
        "    else (x[0],x[3]),\n",
        "    axis=1,\n",
        "    result_type=\"expand\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "ndHnlH8FhYcT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f70bca-73a0-49dd-df63-d1761096968e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated Interjecti... from fre to nl >>> Tussenwerp...\n",
            "Translated Interjecti... from fre to en >>> Interjecti...\n",
            "Translated Interjecti... from fre to fr >>> Interjecti...\n",
            "Translated Interjecti... from fre to de >>> Zwischenru...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_w_tr[\"word_nutri_notes_translation\"] = df_w_tr[\"word_nutri_notes_translation\"].map(\n",
        "    lambda x: np.nan if isinstance(x, str) and (x.isspace() or not x) else x)\n",
        "df_w_tr[\"word_nutri_notes_translation_status\"] = df_w_tr[\"word_nutri_notes_translation_status\"].map(\n",
        "    lambda x: np.nan if isinstance(x, str) and (x.isspace() or not x) else x)"
      ],
      "metadata": {
        "id": "545NBzNJmOR_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# notes et nutri-notes\n",
        "# translate if necessary # status == NaN OR START\n",
        "df_w_tr[[\"word_nutri_notes_translation\",\"word_nutri_notes_translation_status\"]] = df_w_tr[\n",
        "    [\"word_nutri_notes_translation\",\n",
        "     \"word_nutri_notes\",\n",
        "     \"word_language\",\n",
        "     \"word_nutri_notes_translation_status\"]].apply(\n",
        "    lambda x:py_modules.word_translate_update_status(\n",
        "        x[1],\n",
        "        \"fre\",\n",
        "        x[2],\n",
        "        x[3],\n",
        "        df_languages)\n",
        "    if ((pd.isna(x[0]) and not pd.isna(x[1])) or x[3]=='update')\n",
        "    else (x[0],x[3]),\n",
        "    axis=1,\n",
        "    result_type=\"expand\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "Im3GnFuamb53"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text To Speech"
      ],
      "metadata": {
        "id": "yLdFj_JtKHYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check language directories\n",
        "audio_path = \"/content/drive/MyDrive/langdeck/assets/audio/ai/\"\n",
        "df_languages[\"lang_id\"].map(lambda x:py_modules.create_gdrive_folder(audio_path, x))\n",
        "# filtre sur les langues disponibles pour TTS (subset)\n",
        "df_languages[\"lang_is_tts\"] = df_languages[\"lang_is_tts\"].map(lambda x:True if x==\"TRUE\" else False)\n",
        "vk_tts = df_languages.loc[df_languages[\"lang_is_tts\"]][\"lang_id\"].to_list()\n",
        "df_tts = df_w_tr.loc[df_w_tr[\"word_language\"].isin(vk_tts)]\n",
        "# Appel TTS sur le subset (ex) : text2speech(\"Diet\", \"et\", audio_path +\"est\" + \"/\" + \"recIFmq8UmSGnpw0v-est.mp3\", False)\n",
        "df_tts[[\"word_translation\",\"word_language\",\"word_audio\",\"word_translation_status\"]].apply(\n",
        "    lambda x:py_modules.text2speech(\n",
        "    x[0],\n",
        "    df_languages.loc[df_languages[\"lang_id\"]==x[1].lower()][\"lang_alpha2\"].values.item(),\n",
        "    audio_path + x[1] + \"/\" + x[2].split(\"/\")[-1],\n",
        "    False)\n",
        "if py_modules.is_audio(audio_path + x[1] + \"/\", x[2].split(\"/\")[-1])==False\n",
        "or x[3].lower()==\"update\"\n",
        "else None,\n",
        "    axis=1)\n",
        "\n",
        "# replace spaces or empty string by Nan\n",
        "df_tts['word_audio_url'] = df_tts['word_audio_url'].map(\n",
        "    lambda x: np.nan\n",
        "    if isinstance(x, str) and (x.isspace() or not x)\n",
        "    else x)\n",
        "\n",
        "#=======================================================\n",
        "# UPLOAD TO CLOUDINARY\n",
        "#=======================================================\n",
        "\n",
        "# upload only if audio_public_url equals NaN (if url exists, file has yet been uploaded)\n",
        "#df_tts.loc[pd.isna(df_tts[\"audio_public_url\"])]\n",
        "df_tts[\"word_audio_url\"] = df_tts[[\"word_language\",\"word_audio\",\"word_audio_url\",\"word_translation_status\"]].apply(\n",
        "    lambda x: py_modules.upload_to_cdn(\n",
        "    cloudinary,\n",
        "    x[0],\n",
        "    audio_path + x[0]+\"/\",\n",
        "    x[1].split(\"/\")[-1],\n",
        "    x[3])\n",
        "    if pd.isna(x[2]) or x[3].lower() == \"update\"\n",
        "    else x[2],\n",
        "    axis=1)\n",
        "\n",
        "# cette fonction donne pour le mot l'url de la version en français\n",
        "df_tts[\"word_audio_url_fr\"] = df_tts[\"word_rec_id\"].map(\n",
        "    lambda x:py_modules.word_get_audio_url_fr(x, df_tts))\n",
        "\n",
        "py_modules.save_df_to_gsheet (wb_intgr, \"tbl_words\", df_tts)"
      ],
      "metadata": {
        "id": "eaTf5wVnKJeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dadb71b-708c-47ec-fb0e-9abbdf03103f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/langdeck/assets/audio/ai/dut\n",
            "/content/drive/MyDrive/langdeck/assets/audio/ai/eng\n",
            "/content/drive/MyDrive/langdeck/assets/audio/ai/fre\n",
            "/content/drive/MyDrive/langdeck/assets/audio/ai/ger\n",
            "/content/drive/MyDrive/langdeck/assets/audio/ai/dut/recVyn4uxhrR2JuNa-dut.mp3(nl) : okay\n",
            "/content/drive/MyDrive/langdeck/assets/audio/ai/eng/recVyn4uxhrR2JuNa-eng.mp3(en) : okay\n",
            "/content/drive/MyDrive/langdeck/assets/audio/ai/fre/recVyn4uxhrR2JuNa-fre.mp3(fr) : okay\n",
            "/content/drive/MyDrive/langdeck/assets/audio/ai/ger/recVyn4uxhrR2JuNa-ger.mp3(de) : okay\n",
            "iso3:dut ; local_folder:/content/drive/MyDrive/langdeck/assets/audio/ai/dut/ ; path:recVyn4uxhrR2JuNa-dut.mp3\n",
            "http://res.cloudinary.com/dhc7ovnwk/video/upload/v1700130228/langdeck/assets/audio/ai/dut/recVyn4uxhrR2JuNa-dut.mp3\n",
            "iso3:eng ; local_folder:/content/drive/MyDrive/langdeck/assets/audio/ai/eng/ ; path:recVyn4uxhrR2JuNa-eng.mp3\n",
            "http://res.cloudinary.com/dhc7ovnwk/video/upload/v1700130229/langdeck/assets/audio/ai/eng/recVyn4uxhrR2JuNa-eng.mp3\n",
            "iso3:fre ; local_folder:/content/drive/MyDrive/langdeck/assets/audio/ai/fre/ ; path:recVyn4uxhrR2JuNa-fre.mp3\n",
            "http://res.cloudinary.com/dhc7ovnwk/video/upload/v1700130230/langdeck/assets/audio/ai/fre/recVyn4uxhrR2JuNa-fre.mp3\n",
            "iso3:ger ; local_folder:/content/drive/MyDrive/langdeck/assets/audio/ai/ger/ ; path:recVyn4uxhrR2JuNa-ger.mp3\n",
            "http://res.cloudinary.com/dhc7ovnwk/video/upload/v1700130230/langdeck/assets/audio/ai/ger/recVyn4uxhrR2JuNa-ger.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phrases"
      ],
      "metadata": {
        "id": "GtdbeuvfI4FO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intégration"
      ],
      "metadata": {
        "id": "-X3WA0BYI6gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cette fonction remplace le markdown rtf employé par Airtable par un tag HTML paramétrable\n",
        "def phrase_words_markdown_to_html_kw (source, id):\n",
        "  temp = re.sub(r'\\n', '', source)\n",
        "  temp = re.sub(r'\\*+\\`', f'<kw>', temp)\n",
        "  target = re.sub(r'\\`\\*+', '<kw>', temp)\n",
        "  return target\n",
        "\n",
        "# cette fonction remplace l'id temporaire par l'id du mot clé\n",
        "def phrase_words_span_rec_id_kw(source, vk_id):\n",
        "  from itertools import count\n",
        "  counter = count(0)\n",
        "  target = re.sub(r'<kw>(.+?)<kw>', lambda x: '<kw>' + vk_id[next(counter)] + '<kw>', source)\n",
        "  return target"
      ],
      "metadata": {
        "id": "YNW0ySXYLRC5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tbd_phrases = Airtable(base_id, \"phrases\", api_key_airtable)\n",
        "vw_phrases_grid = tbd_phrases.get_all(\n",
        "    view='view_grid',\n",
        "    sort=['phrase_related_story','phrase_paragraph','phrase_position'],\n",
        "    formula=active_filter,\n",
        "    )\n",
        "\n",
        "#=======================================================\n",
        "# Transfo en dataframe\n",
        "#=======================================================\n",
        "df_phrases = pd.DataFrame.from_records((r['fields'] for r in vw_phrases_grid))\n",
        "df_phrases.rename(columns={'phrase_words': 'phrase_words_rec_id'}, inplace=True)\n",
        "df_phrases[\"phrase_words\"] = df_phrases[\"phrase_words_rec_id\"].map(\n",
        "    lambda x:py_modules.get_word_lemma_by_id(tbd_words, x),\n",
        "    na_action=\"ignore\")\n",
        "# récupérer la saynète à partir de son id\n",
        "df_phrases.rename(columns={'phrase_related_story': 'phrase_related_story_rec_id'}, inplace=True)\n",
        "df_phrases[\"phrase_related_story\"] = df_phrases[\"phrase_related_story_rec_id\"].map(\n",
        "    lambda x:py_modules.get_airtable_column_by_id(tbd_stories, x, \"story_name\"),\n",
        "    na_action=\"ignore\")\n",
        "\n",
        "df_phrases[\"phrase_html\"] = df_phrases[[\"phrase_rtf\",\"phrase_rec_id\"]].apply(\n",
        "    lambda x:py_modules.phrase_words_markdown_to_html(x[0], x[1]),\n",
        "    axis=1)\n",
        "\n",
        "df_phrases[\"phrase_html\"] = df_phrases[[\"phrase_html\",\"phrase_words_rec_id\"]].apply(\n",
        "    lambda x:py_modules.phrase_words_span_rec_id(x[0], x[1])\n",
        "    if type(x[1])==list\n",
        "    else np.nan,\n",
        "    axis=1)\n",
        "\n",
        "df_phrases[\"phrase_html_rec_id\"] = df_phrases[[\"phrase_rtf\",\"phrase_rec_id\"]].apply(\n",
        "    lambda x:phrase_words_markdown_to_html_kw(x[0], x[1]),\n",
        "    axis=1)\n",
        "\n",
        "df_phrases[\"phrase_html_rec_id\"] = df_phrases[[\"phrase_html_rec_id\",\"phrase_words_rec_id\"]].apply(\n",
        "    lambda x:phrase_words_span_rec_id_kw(x[0], x[1])\n",
        "    if type(x[1])==list\n",
        "    else np.nan,\n",
        "    axis=1)\n",
        "\n",
        "df_phrases[\"phrase_html_kw\"] = df_phrases[[\"phrase_rtf\",\"phrase_rec_id\"]].apply(\n",
        "    lambda x:phrase_words_markdown_to_html_kw(x[0], x[1]),\n",
        "    axis=1)"
      ],
      "metadata": {
        "id": "FKVISRJDMdaH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vk_col_phrases = [\n",
        "    \"phrase_rec_id\",\n",
        "    \"phrase\",\n",
        "    \"phrase_words\",\n",
        "    \"phrase_words_rec_id\",\n",
        "    \"phrase_html\",\n",
        "    \"phrase_html_rec_id\",\n",
        "    \"phrase_html_kw\",\n",
        "    \"phrase_related_story\",\n",
        "    \"phrase_related_story_rec_id\",\n",
        "    \"phrase_paragraph\",\n",
        "    \"phrase_position\",\n",
        "    \"phrase_status\",\n",
        "    \"phrase_notes\",\n",
        "    \"phrase_notes_2\",\n",
        "    \"phrase_notes_status\",\n",
        "    \"phrase_notes_2_status\",\n",
        "    ]\n",
        "df_phrases = df_phrases[vk_col_phrases]\n",
        "\n",
        "#=======================================================\n",
        "# Ajout des langues en colonnes\n",
        "#=======================================================\n",
        "# df_languages = pd.DataFrame.from_records((r['fields'] for r in vw_lang_grid))\n",
        "# on transpose chaque trigramme de langue en une colonne supplémentaire (values n'a pas d'importance car on vide la table ensuite)\n",
        "df_t = df_languages.pivot(columns='lang_id', values='lang_alpha3')\n",
        "df_t = df_t[0:0]\n",
        "df_phrases = pd.concat([df_phrases, df_t.reindex(df_phrases.index)], axis=1)\n",
        "#=======================================================\n",
        "#---- Transposition des colonnes de langues en lignes\n",
        "#=======================================================\n",
        "df_phr_temp = pd.melt(df_phrases,\n",
        "        id_vars = vk_col_phrases,\n",
        "        var_name = \"phrase_language\",\n",
        "        value_name = \"translation\")\n",
        "# hash incl. language iso3\n",
        "df_phr_temp[\"phrase_translation_id\"] = df_phr_temp[['phrase_rec_id', 'phrase_language']].apply(\n",
        "    lambda x: \"{}-{}\".format(x[0],x[1]),\n",
        "    axis=1)\n",
        "# left join to include translations\n",
        "df_phr_temp.drop(columns=[\"translation\",], axis=1, inplace=True)\n",
        "\n",
        "#=======================================================\n",
        "#---- Merge avec les traductions existantes\n",
        "#=======================================================\n",
        "df_tbl_phrases = py_modules.load_df_from_gsheet (wb_intgr, \"tbl_phrases\")\n",
        "df_phr_tr = pd.merge(\n",
        "    df_phr_temp,\n",
        "    df_tbl_phrases[[\n",
        "        \"phrase_translation_id\",\n",
        "        \"phrase_translation\",\n",
        "        \"phrase_translation_status\",\n",
        "        \"phrase_audio\",\n",
        "        \"phrase_audio_url\",\n",
        "        \"phrase_audio_url_fr\",\n",
        "        \"phrase_notes_translation\",\n",
        "        \"phrase_notes_translation_status\",\n",
        "        \"phrase_notes_2_translation\",\n",
        "        \"phrase_notes_2_translation_status\",\n",
        "        ]],\n",
        "    on=\"phrase_translation_id\",\n",
        "    how=\"left\")"
      ],
      "metadata": {
        "id": "ICiRqstsJBt7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_phr_tr[\"phrase_notes_translation\"] = df_phr_tr[\"phrase_notes_translation\"].map(\n",
        "    lambda x: np.nan if isinstance(x, str) and (x.isspace() or not x) else x)\n",
        "df_phr_tr[\"phrase_notes_translation_status\"] = df_phr_tr[\"phrase_notes_translation_status\"].map(\n",
        "    lambda x: np.nan if isinstance(x, str) and (x.isspace() or not x) else x)\n",
        "df_phr_tr[\"phrase_notes_2_translation\"] = df_phr_tr[\"phrase_notes_2_translation\"].map(\n",
        "    lambda x: np.nan if isinstance(x, str) and (x.isspace() or not x) else x)\n",
        "df_phr_tr[\"phrase_notes_2_translation_status\"] = df_phr_tr[\"phrase_notes_2_translation_status\"].map(\n",
        "    lambda x: np.nan if isinstance(x, str) and (x.isspace() or not x) else x)"
      ],
      "metadata": {
        "id": "y7GCsDnhNr8-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traduction"
      ],
      "metadata": {
        "id": "CMYb9eXdI9AV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traductions : mots à ne pas traduire\n",
        "En attendant d'avoir les fonctionnalités de DeepL, on ignore les tags\n",
        "```\n",
        "def phrase_notes_markdown_to_html_kw (source):\n",
        "  temp = re.sub(r'\\n', '', source)\n",
        "  temp = re.sub(r'\\*+\\`', f'<span translate=\"no\">', temp)\n",
        "  target = re.sub(r'\\`\\*+', '</span>', temp)\n",
        "  return target\n",
        "  \n",
        "def phrase_notes_markdown_to_html_kw_2 (source):\n",
        "  temp = re.sub(r'\\n', '', source)\n",
        "  temp = re.sub(r'\\*+\\`', f'<code>', temp)\n",
        "  target = re.sub(r'\\`\\*+', '</code>', temp)\n",
        "  return target\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "cmWiAM7jL1r7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cette fonction remplace le markdown rtf employé par Airtable par un tag HTML paramétrable\n",
        "def phrase_notes_markdown_to_html_kw_2 (source):\n",
        "  temp = re.sub(r'\\n', '', source)\n",
        "  temp = re.sub(r'\\*+\\`', f'', temp)\n",
        "  target = re.sub(r'\\`\\*+', '', temp)\n",
        "  return target"
      ],
      "metadata": {
        "id": "uilYf-5RL-4L"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_phr_tr[\"phrase_notes\"] = df_phr_tr[\"phrase_notes\"].map(lambda x:phrase_notes_markdown_to_html_kw_2(x) if not pd.isna(x) else np.nan)\n",
        "df_phr_tr[\"phrase_notes_2\"] = df_phr_tr[\"phrase_notes_2\"].map(lambda x:phrase_notes_markdown_to_html_kw_2(x) if not pd.isna(x) else np.nan)"
      ],
      "metadata": {
        "id": "QCcabo9reMTr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# notes\n",
        "# translate if necessary # status == NaN OR START\n",
        "df_phr_tr[[\"phrase_notes_translation\",\"phrase_notes_translation_status\"]] = df_phr_tr[\n",
        "    [\"phrase_notes_translation\",\n",
        "     \"phrase_notes\",\n",
        "     \"phrase_language\",\n",
        "     \"phrase_notes_translation_status\",\n",
        "     \"phrase_notes_status\",\n",
        "     ]].apply(\n",
        "    lambda x:py_modules.word_translate_update_status(\n",
        "        x[1],\n",
        "        \"fre\",\n",
        "        x[2],\n",
        "        x[3],\n",
        "        df_languages)\n",
        "    if ((pd.isna(x[0]) and not pd.isna(x[1])) or x[3]=='Start' or x[4]=='update')\n",
        "    else (x[0],x[3]),\n",
        "    axis=1,\n",
        "    result_type=\"expand\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "WKy4NOgwOiPq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# notes\n",
        "# translate if necessary # status == NaN OR START\n",
        "df_phr_tr[[\"phrase_notes_2_translation\",\"phrase_notes_2_translation_status\"]] = df_phr_tr[\n",
        "    [\"phrase_notes_2_translation\",\n",
        "     \"phrase_notes_2\",\n",
        "     \"phrase_language\",\n",
        "     \"phrase_notes_2_translation_status\",\n",
        "     \"phrase_notes_2_status\",\n",
        "     ]].apply(\n",
        "    lambda x:py_modules.word_translate_update_status(\n",
        "        x[1],\n",
        "        \"fre\",\n",
        "        x[2],\n",
        "        x[3],\n",
        "        df_languages)\n",
        "    if ((pd.isna(x[0]) and not pd.isna(x[1])) or x[3]=='Start' or x[4]=='update')\n",
        "    else (x[0],x[3]),\n",
        "    axis=1,\n",
        "    result_type=\"expand\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "JDoD8WL7O6FY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_phr_tr[\"phrase_translation\"] = df_phr_tr[\"phrase_translation\"].map(\n",
        "    lambda x: np.nan if isinstance(x, str) and (x.isspace() or not x) else x)\n",
        "df_phr_tr[\"phrase_translation_status\"] = df_phr_tr[\"phrase_translation_status\"].map(\n",
        "    lambda x: np.nan if isinstance(x, str) and (x.isspace() or not x) else x)\n",
        "# translate if necessary # status == NaN OR START\n",
        "df_phr_tr[[\"phrase_translation\",\"phrase_translation_status\"]] = df_phr_tr[[\n",
        "    \"phrase_translation\",\n",
        "    \"phrase\",\n",
        "    \"phrase_language\",\n",
        "    \"phrase_translation_status\",\n",
        "    \"phrase_status\",\n",
        "    ]].apply(\n",
        "    lambda x:py_modules.word_translate_update_status(\n",
        "        x[1],\n",
        "        \"fre\",\n",
        "        x[2],\n",
        "        x[3],\n",
        "        df_languages)\n",
        "    if (pd.isna(x[0]) or pd.isna(x[3]) or x[3]=='Start' or x[4]==\"update\")\n",
        "    else (x[0],x[3]),\n",
        "    axis=1,\n",
        "    result_type=\"expand\"\n",
        "    )\n",
        "\n",
        "# emplacement du fichier audio correspondant au mot traduit\n",
        "df_phr_tr[\"phrase_audio\"] = df_phr_tr[[\"phrase_translation_id\",\"phrase_language\"]].apply(\n",
        "    lambda x:\"assets/audio/ai/\"+x[1]+\"/\"+str(x[0])+\".mp3\",\n",
        "    axis=1)"
      ],
      "metadata": {
        "id": "2UfyR6J-Jfud"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text To Speech"
      ],
      "metadata": {
        "id": "W6DnPHBuI_r4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check language directories\n",
        "audio_path = \"/content/drive/MyDrive/langdeck/assets/audio/ai/\"\n",
        "df_languages = pd.DataFrame.from_records((r['fields'] for r in vw_lang_grid))\n",
        "df_languages[\"lang_id\"].map(lambda x:py_modules.create_gdrive_folder(audio_path, x))\n",
        "# filtre sur les langues disponibles pour TTS (subset)\n",
        "df_languages[\"lang_is_tts\"] = df_languages[\"lang_is_tts\"].map(lambda x:True if x.upper()==\"TRUE\" else False)\n",
        "vk_tts = df_languages.loc[df_languages[\"lang_is_tts\"]][\"lang_id\"].to_list()\n",
        "df_tts = df_phr_tr.loc[df_phr_tr[\"phrase_language\"].isin(vk_tts)]\n",
        "df_tts[\"phrase_translation_status\"] = df_tts[[\"phrase_translation_status\",\"phrase_status\"]].apply(\n",
        "    lambda x:\n",
        "    x[1] if x[1].lower() == \"update\" else x[0],\n",
        "    axis=1)\n",
        "# Appel TTS sur le subset (ex) : text2speech(\"Diet\", \"et\", audio_path +\"est\" + \"/\" + \"recIFmq8UmSGnpw0v-est.mp3\", False)\n",
        "df_tts[[\n",
        "    \"phrase_translation\",\n",
        "    \"phrase_language\",\n",
        "    \"phrase_audio\",\n",
        "    \"phrase_translation_status\",\n",
        "    ]].apply(\n",
        "    lambda x:py_modules.text2speech(\n",
        "      x[0],\n",
        "      df_languages.loc[df_languages[\"lang_id\"]==x[1].lower()][\"lang_alpha2\"].values.item(),\n",
        "      audio_path + x[1] + \"/\" + x[2].split(\"/\")[-1],\n",
        "      False\n",
        "    )\n",
        "    if py_modules.is_audio(audio_path + x[1] + \"/\", x[2].split(\"/\")[-1])==False\n",
        "      or x[3].lower()==\"update\"\n",
        "    else None,\n",
        "    axis=1)\n",
        "\n",
        "# replace spaces or empty string by Nan\n",
        "df_tts['phrase_audio_url'] = df_tts['phrase_audio_url'].map(\n",
        "    lambda x: np.nan\n",
        "    if isinstance(x, str) and (x.isspace() or not x)\n",
        "    else x)\n",
        "\n",
        "#=======================================================\n",
        "# UPLOAD TO CLOUDINARY\n",
        "#=======================================================\n",
        "\n",
        "# upload only if audio_public_url equals NaN (if url exists, file has yet been uploaded)\n",
        "#df_tts.loc[pd.isna(df_tts[\"audio_public_url\"])]\n",
        "df_tts[\"phrase_audio_url\"] = df_tts[[\n",
        "    \"phrase_language\",\n",
        "    \"phrase_audio\",\n",
        "    \"phrase_audio_url\",\n",
        "    \"phrase_translation_status\",\n",
        "    ]].apply(\n",
        "    lambda x: py_modules.upload_to_cdn(\n",
        "    cloudinary,\n",
        "    x[0],\n",
        "    audio_path + x[0]+\"/\",\n",
        "    x[1].split(\"/\")[-1],\n",
        "    x[3])\n",
        "    if pd.isna(x[2])\n",
        "      or x[3].lower() == \"update\"\n",
        "    else x[2],\n",
        "    axis=1)\n",
        "\n",
        "# cette fonction donne pour le mot l'url de la version en français\n",
        "df_tts[\"phrase_audio_url_fr\"] = df_tts[\"phrase_rec_id\"].map(\n",
        "    lambda x:py_modules.phrase_get_audio_url_fr(x, df_tts))"
      ],
      "metadata": {
        "id": "9EY-UoyuI5_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c4d50fd-b022-425d-95bb-5a2fc5fcb241"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/langdeck/assets/audio/ai/dut\n",
            "/content/drive/MyDrive/langdeck/assets/audio/ai/eng\n",
            "/content/drive/MyDrive/langdeck/assets/audio/ai/fre\n",
            "/content/drive/MyDrive/langdeck/assets/audio/ai/ger\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#=======================================================\n",
        "# TRADUCTION DES MOTS ASSOCIES\n",
        "#=======================================================\n",
        "df_tbl_stories = py_modules.load_df_from_gsheet (wb_intgr, \"tbl_stories\")\n",
        "df_tbl_words = py_modules.load_df_from_gsheet (wb_intgr, \"tbl_words\")\n",
        "# # construit un id concaténé avec le code langue pour chaque element du vecteur\n",
        "df_tts[\"phrase_words_tr_rec_id\"] = df_tts[[\"phrase_words_rec_id\",\"phrase_language\"]].apply(\n",
        "    lambda x:py_modules.set_phrase_words_tr_rec_id(\n",
        "        x[0],\n",
        "        x[1])\n",
        "    if type(x[0])==list\n",
        "    else np.nan,\n",
        "    axis=1)\n",
        "# récupère le mot traduit depuis son identifiant\n",
        "df_tts[\"phrase_words_tr\"] = df_tts[\"phrase_words_tr_rec_id\"].map(\n",
        "    lambda x:py_modules.set_phrase_words_tr(x, df_tbl_words),\n",
        "    na_action='ignore')\n",
        "#=======================================================\n",
        "# TRADUCTION DES META DONNEES (STORY, THEME, ETC.)\n",
        "#=======================================================\n",
        "df_tts[\"phrase_related_story_tr_rec_id\"] = df_tts[[\"phrase_related_story_rec_id\",\"phrase_language\"]].apply(\n",
        "    lambda x:py_modules.set_phrase_words_tr_rec_id(\n",
        "        x[0],\n",
        "        x[1])\n",
        "    if type(x[0])==list\n",
        "    else np.nan,\n",
        "    axis=1)\n",
        "\n",
        "# récupère le mot traduit depuis son identifiant\n",
        "df_tts[\"phrase_related_story_tr\"] = df_tts[\"phrase_related_story_tr_rec_id\"].map(\n",
        "    lambda x:py_modules.get_story_tr(x, df_tbl_stories),\n",
        "    na_action='ignore')"
      ],
      "metadata": {
        "id": "iB0qj_c9JkSF"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# on rebascule les états si il y a eu update\n",
        "df_tts[\"phrase_translation_status\"] = df_tts[[\"phrase_translation_status\",\"phrase_status\"]].apply(\n",
        "    lambda x:\n",
        "    \"Pending\" if x[1].lower() == \"update\" else x[0],\n",
        "    axis=1)\n",
        "\n",
        "py_modules.save_df_to_gsheet (wb_intgr, \"tbl_phrases\", df_tts)"
      ],
      "metadata": {
        "id": "Z9uh55YNJp8T"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformation format JSON"
      ],
      "metadata": {
        "id": "CTNsOzsecgIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stories"
      ],
      "metadata": {
        "id": "QXRLChADKZpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_stories = py_modules.load_df_from_gsheet(wb_intgr, \"tbl_stories\")\n",
        "df_stories.sort_values (\n",
        "    by=[\"story_language\",\n",
        "        \"story_level\",\n",
        "        \"story_name\",\n",
        "        \"story_episode\",],\n",
        "    inplace=True)\n",
        "vk_stories_cols = [\n",
        "    \"story_rec_id\",\n",
        "    \"story_translation_id\",\n",
        "    \"story_name\",\n",
        "    \"story_translation\",\n",
        "    \"story_level\",\n",
        "    \"story_episode\",\n",
        "    \"story_audio_url\",\n",
        "    \"story_audio_url_fr\",\n",
        "    \"story_illustration\",\n",
        "    \"story_desc\",\n",
        "    \"story_desc_translation\",\n",
        "    ]\n",
        "vk_stories_vals = df_stories.groupby([\"story_rec_id\"])[vk_stories_cols].apply(\n",
        "      lambda x: list(map(tuple, x.values.tolist()))).to_list()"
      ],
      "metadata": {
        "id": "8uihZifmLBtX"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phrases"
      ],
      "metadata": {
        "id": "EWhUQaIUttq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_phrases = py_modules.load_df_from_gsheet(wb_intgr, \"tbl_phrases\") # load source sheet\n",
        "df_phrases[\"phrase_related_story\"] = df_phrases[\"phrase_related_story\"].map(lambda x:ast.literal_eval(x)[0])\n",
        "df_phrases[\"phrase_related_story_rec_id\"] = df_phrases[\"phrase_related_story_rec_id\"].map(lambda x:ast.literal_eval(x)[0])\n",
        "df_phrases[\"phrase_related_story_tr\"] = df_phrases[\"phrase_related_story_tr\"].map(lambda x:ast.literal_eval(x)[0])\n",
        "df_phrases[\"phrase_related_story_tr_rec_id\"] = df_phrases[\"phrase_related_story_tr_rec_id\"].map(lambda x:ast.literal_eval(x)[0])\n",
        "df_themes = py_modules.load_df_from_gsheet(wb_intgr, \"tbl_themes\") # load source sheet\n",
        "df_phrases.sort_values(by=['phrase_language','phrase_related_story','phrase_paragraph','phrase_position'], inplace=True)\n",
        "\n",
        "# merge phrases + story => vue à plat avec les données étendues\n",
        "df_phr_ext = pd.merge(df_phrases, df_stories[vk_stories_cols],\n",
        "         left_on=\"phrase_related_story_tr_rec_id\",\n",
        "         right_on=\"story_translation_id\",\n",
        "         how=\"left\")\n",
        "\n",
        "# vector of columns\n",
        "vk_phrases_cols = [\n",
        "    \"phrase_language\",\n",
        "    \"phrase_related_story\",\n",
        "    \"phrase_related_story_rec_id\",\n",
        "    \"phrase_paragraph\",\n",
        "    \"phrase_position\",\n",
        "    \"phrase_rec_id\",\n",
        "    \"phrase\",\n",
        "    \"phrase_words\",\n",
        "    \"phrase_words_rec_id\",\n",
        "    \"phrase_words_tr\",\n",
        "    \"phrase_words_tr_rec_id\",\n",
        "    \"phrase_html\",\n",
        "    \"phrase_html_rec_id\",\n",
        "    \"phrase_html_kw\",\n",
        "    \"phrase_translation\",\n",
        "    \"phrase_audio\",\n",
        "    \"phrase_audio_url\",\n",
        "    \"phrase_audio_url_fr\",\n",
        "    \"phrase_related_story_tr\",\n",
        "    \"phrase_notes\",\n",
        "    \"phrase_notes_2\",\n",
        "    \"phrase_notes_translation\",\n",
        "    \"phrase_notes_2_translation\",\n",
        "    \"story_rec_id\",\n",
        "    \"story_translation_id\",\n",
        "    \"story_name\",\n",
        "    \"story_translation\",\n",
        "    \"story_level\",\n",
        "    \"story_episode\",\n",
        "    \"story_audio_url\",\n",
        "    \"story_audio_url_fr\",\n",
        "    \"story_illustration\",\n",
        "    \"story_desc\",\n",
        "    \"story_desc_translation\",\n",
        "    ] # fields (columns)\n",
        "\n",
        "# vector of values grouped by language\n",
        "vk_phrases_vals = df_phr_ext.groupby([\"phrase_language\"])[vk_phrases_cols].apply(\n",
        "      lambda x: list(map(tuple, x.values.tolist()))).to_list()\n"
      ],
      "metadata": {
        "id": "YIX0aL98tohT"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Words and keywords"
      ],
      "metadata": {
        "id": "pvh679Z0tyQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_words = py_modules.load_df_from_gsheet(wb_intgr, \"tbl_words\")\n",
        "df_words[\"order\"] = df_words[\"word_type\"].map(lambda x:1 if x==\"Lemma\" else 2 if x==\"Expression\" else 3)\n",
        "df_words.sort_values(by=['word_language','word','order',], inplace=True)\n",
        "vk_word_cols = [\n",
        "    \"word_language\",\n",
        "    \"word\",\n",
        "    \"word_rec_id\",\n",
        "    \"order\",\n",
        "    \"word_type\",\n",
        "    \"word_translation_id\",\n",
        "    \"word_translation\",\n",
        "    \"word_lemmas\",\n",
        "    \"word_lemmas_rec_id\",\n",
        "    \"word_audio\",\n",
        "    \"word_audio_url\",\n",
        "    \"word_audio_url_fr\",\n",
        "    \"word_lemmas_tr_rec_id\",\n",
        "    \"word_lemmas_tr\",\n",
        "    \"word_notes\",\n",
        "    \"word_nutri_notes\",\n",
        "    \"word_notes_translation\",\n",
        "    \"word_nutri_notes_translation\",\n",
        "    ] # fields (columns)\n",
        "\n",
        "vk_word_vals = df_words.groupby([\"word_language\"])[vk_word_cols].apply(\n",
        "      lambda x: list(map(tuple, x.values.tolist()))).to_list()"
      ],
      "metadata": {
        "id": "6qogpto4djU_"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keywords"
      ],
      "metadata": {
        "id": "l-TYiteL7W3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f_phrases_list_to_dict_by_col(col_name, vkp):\n",
        "  vkf = list(dict.fromkeys(list(map(\n",
        "        lambda x: x[col_name],\n",
        "        filter(lambda d: d['phrase_rec_id'] in vkp,\n",
        "               sorted(vk_lang_dict, key=lambda x: x[\"phrase_paragraph\"]))))))[0]\n",
        "  return vkf\n",
        "\n",
        "def f_words_get_value_by_col (df, col_key, col_name, key):\n",
        "  cval = df.loc[df[col_key]==key][col_name].values.item()\n",
        "  return cval\n"
      ],
      "metadata": {
        "id": "TZSSYcJFYy8J"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Languages"
      ],
      "metadata": {
        "id": "Q00yk1XR91d3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_languages = py_modules.load_df_from_gsheet (wb_intgr, \"tbl_languages\")\n",
        "df_languages[\"lang_is_tts\"] = df_languages[\"lang_is_tts\"].map(lambda x:True if x==\"TRUE\" else False)\n",
        "df_languages[\"lang_is_available\"] = df_languages[\"lang_is_available\"].map(lambda x:True if x==\"TRUE\" else False)\n",
        "df_ref_lang = py_modules.load_df_from_gsheet (wb_intgr, \"ref_languages\")\n",
        "# merge pour récupérer des infos de référentiels\n",
        "df_languages = pd.merge (df_languages,\n",
        "          df_ref_lang[[\"language_uid\",\"country_ref\",\"flag_icon\"]],\n",
        "          left_on=\"lang_id\",\n",
        "          right_on=\"language_uid\",\n",
        "          how=\"left\")\n",
        "df_languages.drop(columns=[\"language_uid\",], axis=1, inplace=True)\n",
        "df_languages.rename(\n",
        "    columns={\"country_ref\":\"lang_country_ref\",\n",
        "             \"flag_icon\":\"lang_flag_icon\"},\n",
        "    inplace=True)\n",
        "# merge pour récupérer des infos de référentiels\n",
        "df_ref_lang = py_modules.load_df_from_gsheet (wb_intgr, \"ref_languages_countries\")\n",
        "df_languages = pd.merge (df_languages,\n",
        "          df_ref_lang[[\"language_uid\",\"language_countries\",]],\n",
        "          left_on=\"lang_id\",\n",
        "          right_on=\"language_uid\",\n",
        "          how=\"left\")\n",
        "df_languages.drop(columns=[\"language_uid\",\"lang_countries_vk\",], axis=1, inplace=True)\n",
        "df_languages.rename(\n",
        "    columns={\"language_countries\":\"lang_countries_vk\",},\n",
        "    inplace=True)\n",
        "# Liste des colonnes pour le dict\n",
        "vk_language_cols = [\n",
        "    \"lang_id\",\n",
        "    \"lang_alpha3\",\n",
        "    \"lang_alpha2_google\",\n",
        "    \"lang_alpha2\",\n",
        "    \"lang_wals\",\n",
        "    \"lang_name_native\",\n",
        "    \"lang_name_en\",\n",
        "    \"lang_name_fr\",\n",
        "    \"lang_is_available\",\n",
        "    \"lang_is_tts\",\n",
        "    \"lang_countries_vk\",\n",
        "    \"lang_country_ref\",\n",
        "    \"lang_flag_icon\",\n",
        "]"
      ],
      "metadata": {
        "id": "jmysyMVYvuHO"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vk_lang = []\n",
        "# pour chaque phrase : on itère\n",
        "for vk_lang_tuple in vk_phrases_vals:\n",
        "  # on transforme le tuple en dict\n",
        "  vk_lang_dict = list(map(lambda x: dict(zip(vk_phrases_cols,x)), vk_lang_tuple))\n",
        "  d_lang = {}\n",
        "  #------L A N G U A G E S----------\n",
        "  d_lang[\"language\"] = list(dict.fromkeys(map(\n",
        "      lambda x:x[\"phrase_language\"],\n",
        "      sorted(vk_lang_dict, key=lambda x: x[\"phrase_language\"]))))[0]\n",
        "  # get all language cols by key\n",
        "  for field in vk_language_cols:\n",
        "    d_lang[field] = df_languages.loc[df_languages[\"lang_id\"]==d_lang[\"language\"]][field].values.item()\n",
        "  # ce vecteur est dans un format string, il faut le caster en array\n",
        "  d_lang[\"lang_countries_vk\"] = ast.literal_eval(d_lang[\"lang_countries_vk\"])\n",
        "  # pour chaque story\n",
        "  vk_stories = []\n",
        "  for el_story in list(dict.fromkeys(list(map(\n",
        "      lambda x: x[\"phrase_related_story\"],\n",
        "      sorted(vk_lang_dict, key=lambda x: x[\"phrase_related_story\"]))))):\n",
        "    d_story = {}\n",
        "    #------S T O R I E S----------\n",
        "    d_story[\"story\"] = el_story\n",
        "\n",
        "    # pour chaque phrase\n",
        "    vk_phrases = []\n",
        "    for phrase_rec_id in list(dict.fromkeys(list(map(\n",
        "        lambda x: x[\"phrase_rec_id\"],\n",
        "        filter(lambda d: d['phrase_related_story'] == el_story,\n",
        "               sorted(vk_lang_dict, key=lambda x: x[\"phrase_paragraph\"])))))):\n",
        "      d_phrase = {}\n",
        "      #------P H R A S E S----------\n",
        "      # pour chaque colonne, on tranforme en dict\n",
        "      for field in vk_phrases_cols:\n",
        "        d_phrase[field] = f_phrases_list_to_dict_by_col(\n",
        "            field,\n",
        "            phrase_rec_id)\n",
        "      d_phrase[\"phrase_rec_id\"] = phrase_rec_id\n",
        "      # rendons à story ce qui appartient à story...\n",
        "      for field in vk_stories_cols:\n",
        "        d_story[field] = d_phrase[field]\n",
        "        d_phrase.pop(field)\n",
        "\n",
        "      # pour chaque mot\n",
        "      vk_words = []\n",
        "      if len(d_phrase[\"phrase_words_tr_rec_id\"])>0:\n",
        "        list_words = ast.literal_eval(d_phrase[\"phrase_words_tr_rec_id\"])\n",
        "        for word in list_words:\n",
        "          #------W O R D S----------\n",
        "          d_word = {}\n",
        "          # on récupère la valeur pour chaque attribut de mot\n",
        "          for field in vk_word_cols:\n",
        "            d_word[field] = f_words_get_value_by_col(\n",
        "                df_words,\n",
        "                \"word_translation_id\",\n",
        "                field,\n",
        "                word)\n",
        "\n",
        "          d_word[\"word_tr_rec_id\"] = word\n",
        "          # lemmes et expressions\n",
        "          vk_lem_exp = []\n",
        "          # si lemmes : on itère le vecteur\n",
        "          if len(d_word[\"word_lemmas_rec_id\"])>0:\n",
        "            list_lems = ast.literal_eval(d_word[\"word_lemmas_rec_id\"])\n",
        "            for lem in list_lems:\n",
        "              #---K E Y W O R D S---\n",
        "              d_lem = {}\n",
        "              # on construit la clé de recherche id + langue\n",
        "              lemkey = lem + \"-\" + d_word[\"word_language\"]\n",
        "              # pour chaque colonne (idem words) : on récupère la valeur à partir de la clé\n",
        "              for field in vk_word_cols:\n",
        "                d_lem[field] = f_words_get_value_by_col(\n",
        "                  df_words,\n",
        "                  \"word_translation_id\",\n",
        "                  field,\n",
        "                  lemkey)\n",
        "              #----------------------\n",
        "              d_lem[\"keyword\"] = lem\n",
        "              vk_lem_exp.append(d_lem)\n",
        "              #----------------------\n",
        "\n",
        "          #----------------------\n",
        "          d_word[\"keywords\"] = vk_lem_exp\n",
        "          vk_words.append(d_word)\n",
        "          #----------------------\n",
        "\n",
        "      #----------------------\n",
        "      d_phrase[\"words\"] = vk_words\n",
        "      vk_phrases.append(d_phrase)\n",
        "      #----------------------\n",
        "\n",
        "    #----------------------\n",
        "    d_story[\"phrases\"] = vk_phrases\n",
        "    #----------------------\n",
        "    vk_stories.append(d_story)\n",
        "\n",
        "\n",
        "  #----------------------\n",
        "  d_lang[\"stories\"] = vk_stories\n",
        "  #----------------------\n",
        "\n",
        "  vk_lang.append(d_lang)\n"
      ],
      "metadata": {
        "id": "Y0Je3YalRmgU"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vk_lang[3]"
      ],
      "metadata": {
        "id": "UqjpdlVHRw-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a41985-5b58-42e5-aa8e-b929752c321e"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'language': 'ger',\n",
              " 'lang_id': 'ger',\n",
              " 'lang_alpha3': 'ger',\n",
              " 'lang_alpha2_google': 'de',\n",
              " 'lang_alpha2': 'de',\n",
              " 'lang_wals': 'ger',\n",
              " 'lang_name_native': 'Deutsch',\n",
              " 'lang_name_en': 'German',\n",
              " 'lang_name_fr': 'Allemand',\n",
              " 'lang_is_available': True,\n",
              " 'lang_is_tts': True,\n",
              " 'lang_countries_vk': [{'country_iso3': 'aut',\n",
              "   'country_iso2': 'AT',\n",
              "   'country_name_fr': 'Autriche',\n",
              "   'popularity': '100.00%',\n",
              "   'popularity_as_float': 1.0,\n",
              "   'speakers': '8,000,000',\n",
              "   'is_official': 'TRUE',\n",
              "   'official': 'Langue officielle',\n",
              "   'national_flag': 'https://res.cloudinary.com/dhc7ovnwk/image/upload/v1670497510/langdeck/assets/flags_100px/at.png',\n",
              "   'xy_coordinates': '47.3333,13.3333'},\n",
              "  {'country_iso3': 'bel',\n",
              "   'country_iso2': 'BE',\n",
              "   'country_name_fr': 'Belgique',\n",
              "   'popularity': '10.00%',\n",
              "   'popularity_as_float': 0.1,\n",
              "   'speakers': '1,200,000',\n",
              "   'is_official': 'TRUE',\n",
              "   'official': '',\n",
              "   'national_flag': 'https://res.cloudinary.com/dhc7ovnwk/image/upload/v1670497510/langdeck/assets/flags_100px/be.png',\n",
              "   'xy_coordinates': '50.8333,4'},\n",
              "  {'country_iso3': 'che',\n",
              "   'country_iso2': 'CH',\n",
              "   'country_name_fr': 'Suisse',\n",
              "   'popularity': '62.00%',\n",
              "   'popularity_as_float': 0.62,\n",
              "   'speakers': '',\n",
              "   'is_official': 'TRUE',\n",
              "   'official': 'Langue officielle.',\n",
              "   'national_flag': 'https://res.cloudinary.com/dhc7ovnwk/image/upload/v1670497510/langdeck/assets/flags_100px/ch.png',\n",
              "   'xy_coordinates': '47,8'},\n",
              "  {'country_iso3': 'cze',\n",
              "   'country_iso2': 'CZ',\n",
              "   'country_name_fr': 'Tchéquie',\n",
              "   'popularity': '15.00%',\n",
              "   'popularity_as_float': 0.15,\n",
              "   'speakers': '1,650,000',\n",
              "   'is_official': 'FALSE',\n",
              "   'official': '',\n",
              "   'national_flag': 'https://res.cloudinary.com/dhc7ovnwk/image/upload/v1670497510/langdeck/assets/flags_100px/cz.png',\n",
              "   'xy_coordinates': '49.75,15.5'},\n",
              "  {'country_iso3': 'deu',\n",
              "   'country_iso2': 'DE',\n",
              "   'country_name_fr': 'Allemagne',\n",
              "   'popularity': '100.00%',\n",
              "   'popularity_as_float': 1.0,\n",
              "   'speakers': '80,000,000',\n",
              "   'is_official': 'TRUE',\n",
              "   'official': 'Langue officielle',\n",
              "   'national_flag': 'https://res.cloudinary.com/dhc7ovnwk/image/upload/v1670497510/langdeck/assets/flags_100px/de.png',\n",
              "   'xy_coordinates': '51,9'},\n",
              "  {'country_iso3': 'dnk',\n",
              "   'country_iso2': 'DK',\n",
              "   'country_name_fr': 'Danemark',\n",
              "   'popularity': '47.00%',\n",
              "   'popularity_as_float': 0.47,\n",
              "   'speakers': '2,820,000',\n",
              "   'is_official': 'FALSE',\n",
              "   'official': '',\n",
              "   'national_flag': 'https://res.cloudinary.com/dhc7ovnwk/image/upload/v1670497510/langdeck/assets/flags_100px/dk.png',\n",
              "   'xy_coordinates': '56,10'},\n",
              "  {'country_iso3': 'fin',\n",
              "   'country_iso2': 'FI',\n",
              "   'country_name_fr': 'Finlande',\n",
              "   'popularity': '18.00%',\n",
              "   'popularity_as_float': 0.18,\n",
              "   'speakers': '1,080,000',\n",
              "   'is_official': 'FALSE',\n",
              "   'official': '',\n",
              "   'national_flag': 'https://res.cloudinary.com/dhc7ovnwk/image/upload/v1670497510/langdeck/assets/flags_100px/fi.png',\n",
              "   'xy_coordinates': '64,26'},\n",
              "  {'country_iso3': 'nld',\n",
              "   'country_iso2': 'NL',\n",
              "   'country_name_fr': 'Pays-Bas',\n",
              "   'popularity': '71.00%',\n",
              "   'popularity_as_float': 0.71,\n",
              "   'speakers': '12,275,900',\n",
              "   'is_official': 'FALSE',\n",
              "   'official': '',\n",
              "   'national_flag': 'https://res.cloudinary.com/dhc7ovnwk/image/upload/v1670497510/langdeck/assets/flags_100px/nl.png',\n",
              "   'xy_coordinates': '52.5,5.75'},\n",
              "  {'country_iso3': 'pol',\n",
              "   'country_iso2': 'PL',\n",
              "   'country_name_fr': 'Pologne',\n",
              "   'popularity': '13.00%',\n",
              "   'popularity_as_float': 0.13,\n",
              "   'speakers': '5,200,000',\n",
              "   'is_official': 'FALSE',\n",
              "   'official': '',\n",
              "   'national_flag': 'https://res.cloudinary.com/dhc7ovnwk/image/upload/v1670497510/langdeck/assets/flags_100px/pl.png',\n",
              "   'xy_coordinates': '52,20'},\n",
              "  {'country_iso3': 'lux',\n",
              "   'country_iso2': 'LU',\n",
              "   'country_name_fr': 'Luxembourg',\n",
              "   'popularity': '81.00%',\n",
              "   'popularity_as_float': 0.81,\n",
              "   'speakers': '486,000',\n",
              "   'is_official': 'TRUE',\n",
              "   'official': 'Langue officielle',\n",
              "   'national_flag': 'https://res.cloudinary.com/dhc7ovnwk/image/upload/v1670497510/langdeck/assets/flags_100px/lu.png',\n",
              "   'xy_coordinates': '49.75,6.1667'},\n",
              "  {'country_iso3': 'svn',\n",
              "   'country_iso2': 'SI',\n",
              "   'country_name_fr': 'Slovénie',\n",
              "   'popularity': '1.00%',\n",
              "   'popularity_as_float': 0.01,\n",
              "   'speakers': '20,000',\n",
              "   'is_official': 'FALSE',\n",
              "   'official': 'Minorité autrichienne.',\n",
              "   'national_flag': 'https://res.cloudinary.com/dhc7ovnwk/image/upload/v1670497510/langdeck/assets/flags_100px/si.png',\n",
              "   'xy_coordinates': '46,15'}],\n",
              " 'lang_country_ref': 'DE',\n",
              " 'lang_flag_icon': 'https://res.cloudinary.com/dhc7ovnwk/image/upload/v1670497510/langdeck/assets/flags_100px/de.png',\n",
              " 'stories': [{'story': 'Le petit-déjeuner',\n",
              "   'story_rec_id': 'recYrnBviiGa6SErr',\n",
              "   'story_translation_id': 'recYrnBviiGa6SErr-ger',\n",
              "   'story_name': 'Le petit-déjeuner',\n",
              "   'story_translation': 'Frühstück',\n",
              "   'story_level': 'Beginner',\n",
              "   'story_episode': 'Part 1',\n",
              "   'story_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1697030276/langdeck/assets/audio/ai/ger/recYrnBviiGa6SErr-ger.mp3',\n",
              "   'story_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1697030274/langdeck/assets/audio/ai/fre/recYrnBviiGa6SErr-fre.mp3',\n",
              "   'story_illustration': 'https://res.cloudinary.com/dhc7ovnwk/image/upload/v1698074882/langdeck/assets/images/saynetes/fdrquegyt56djolu1uc2.jpg',\n",
              "   'story_desc': \"Une leçon de niveau facile pour débuter. Démarrons la journée par un petit-déjeuner pour apprendre les premiers mots et quelques règles simples de l'usage du français dans la vie courante.\",\n",
              "   'story_desc_translation': 'Eine einfache Lektion für den Anfang. Beginnen wir den Tag mit einem Frühstück, um die ersten Wörter und einige einfache Regeln für die Verwendung der französischen Sprache im Alltag zu lernen.',\n",
              "   'phrases': [{'phrase_language': 'ger',\n",
              "     'phrase_related_story': 'Le petit-déjeuner',\n",
              "     'phrase_related_story_rec_id': 'recYrnBviiGa6SErr',\n",
              "     'phrase_paragraph': '1',\n",
              "     'phrase_position': '1',\n",
              "     'phrase_rec_id': 'recUTxQtXiufCX1Nt',\n",
              "     'phrase': 'Bonjour, tu veux du café ?',\n",
              "     'phrase_words': \"['Café']\",\n",
              "     'phrase_words_rec_id': \"['recgLzTREq2YHlWn9']\",\n",
              "     'phrase_words_tr': \"['Kaffee']\",\n",
              "     'phrase_words_tr_rec_id': \"['recgLzTREq2YHlWn9-ger']\",\n",
              "     'phrase_html': 'Bonjour, tu veux du <span id=\"recgLzTREq2YHlWn9\">café</span> ?',\n",
              "     'phrase_html_rec_id': 'Bonjour, tu veux du <kw>recgLzTREq2YHlWn9<kw> ?',\n",
              "     'phrase_html_kw': 'Bonjour, tu veux du <kw>café<kw> ?',\n",
              "     'phrase_translation': 'Hallo, möchtest du einen Kaffee?',\n",
              "     'phrase_audio': 'assets/audio/ai/ger/recUTxQtXiufCX1Nt-ger.mp3',\n",
              "     'phrase_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696947299/langdeck/assets/audio/ai/ger/recUTxQtXiufCX1Nt-ger.mp3',\n",
              "     'phrase_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696947286/langdeck/assets/audio/ai/fre/recUTxQtXiufCX1Nt-fre.mp3',\n",
              "     'phrase_related_story_tr': 'Frühstück',\n",
              "     'phrase_notes': \"En français, il y a deux façons de s’adresser à des personnes, en fonction du type de relation : en utilisant tu ou vous.Dans une relation amicale ou familiale, on utilise tu (Quel âge as-tu ? Comment t’appelles-tu ? D’où viens-tu ?). Pour s’adresser à des personnes que l'on ne connaît pas, dans les lieux publics comme les magasins, les services ou les administrations, on utilise le pluriel de politesse vous (Quel âge avez-vous ? Comment vous appelez-vous ? Qui êtes-vous ?).Dans les premiers temps d’une relation de travail, on se dit vous, même si on a le même âge.\",\n",
              "     'phrase_notes_2': \"Tu veux, c’est le verbe vouloir conjugué au présent. Son sujet est tu, la deuxième personne du singulier. La terminaison -x s’utilise avec les sujets je et tu : je veux, tu veux.Quand on inverse l’ordre du sujet et du verbe, notamment dans les questions, on écrit veux-tu avec un trait d’union. Exemple : veux-tu du café ?Pour s’adresser poliment à des personnes que l'on ne connaît pas, on utilise le pluriel de politesse « vous »  et on met le verbe en premier (Voulez-vous du café ?). Dans le langage familier, il est courant d'inverser l'ordre (Tu veux du café ? Vous voulez du thé ?).\",\n",
              "     'phrase_notes_translation': 'Im Französischen gibt es je nach Art der Beziehung zwei Möglichkeiten, Menschen anzusprechen: tu oder vous. In einer freundschaftlichen oder familiären Beziehung verwenden wir tu (Wie alt bist du? Wie heißt du – du? Woher kommst du?) ). Um Personen anzusprechen, die Sie nicht kennen, verwenden Sie an öffentlichen Orten wie Geschäften, Dienstleistungen oder Verwaltungen den höflichen Plural „Sie“ (Wie alt sind Sie? Wie heißt Sie? Wer sind Sie?). In der Anfangsphase einer Arbeit In einer Beziehung nennen wir uns Du, auch wenn wir gleich alt sind.',\n",
              "     'phrase_notes_2_translation': 'You want ist das im Präsens konjugierte Verb want. Sein Subjekt ist tu, die zweite Person Singular. Die Endung -x wird bei den Subjekten I und You verwendet: I want, you want. Wenn wir die Reihenfolge von Subjekt und Verb vertauschen, insbesondere bei Fragen, schreiben wir do you want mit einem Bindestrich. Beispiel: Möchten Sie einen Kaffee? Um Menschen, die Sie nicht kennen, höflich anzusprechen, verwenden wir den höflichen Plural „Sie“ und setzen das Verb an die erste Stelle (Möchten Sie einen Kaffee?). In der Umgangssprache ist es üblich, die Reihenfolge umzukehren (Möchten Sie Kaffee? Möchten Sie Tee?).',\n",
              "     'words': [{'word_language': 'ger',\n",
              "       'word': 'Café',\n",
              "       'word_rec_id': 'recgLzTREq2YHlWn9',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'recgLzTREq2YHlWn9-ger',\n",
              "       'word_translation': 'Kaffee',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/recgLzTREq2YHlWn9-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679468/langdeck/assets/audio/ai/ger/recgLzTREq2YHlWn9-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679456/langdeck/assets/audio/ai/fre/recgLzTREq2YHlWn9-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': 'En France, au petit-déjeuner, on boit surtout du café, avec ou sans lait.',\n",
              "       'word_nutri_notes': 'Le café ne contient presque pas de calories, mais le sucre et la crème qu’on lui ajoute peuvent être très riches. Pour pleinement profiter de ses bienfaits, mieux vaut boire son café noir.',\n",
              "       'word_notes_translation': 'In Frankreich trinken wir zum Frühstück hauptsächlich Kaffee, mit oder ohne Milch.',\n",
              "       'word_nutri_notes_translation': 'Kaffee enthält fast keine Kalorien, aber der zugesetzte Zucker und die Sahne können sehr reichhaltig sein. Um die Vorteile voll auszuschöpfen, ist es besser, Ihren Kaffee schwarz zu trinken.',\n",
              "       'word_tr_rec_id': 'recgLzTREq2YHlWn9-ger',\n",
              "       'keywords': []}]},\n",
              "    {'phrase_language': 'ger',\n",
              "     'phrase_related_story': 'Le petit-déjeuner',\n",
              "     'phrase_related_story_rec_id': 'recYrnBviiGa6SErr',\n",
              "     'phrase_paragraph': '2',\n",
              "     'phrase_position': '2',\n",
              "     'phrase_rec_id': 'recUA7LJgIjxS3OGI',\n",
              "     'phrase': 'Non merci, pas de café',\n",
              "     'phrase_words': \"['Café']\",\n",
              "     'phrase_words_rec_id': \"['recgLzTREq2YHlWn9']\",\n",
              "     'phrase_words_tr': \"['Kaffee']\",\n",
              "     'phrase_words_tr_rec_id': \"['recgLzTREq2YHlWn9-ger']\",\n",
              "     'phrase_html': 'Non merci, pas de <span id=\"recgLzTREq2YHlWn9\">café</span>',\n",
              "     'phrase_html_rec_id': 'Non merci, pas de <kw>recgLzTREq2YHlWn9<kw>',\n",
              "     'phrase_html_kw': 'Non merci, pas de <kw>café<kw>',\n",
              "     'phrase_translation': 'Nein danke, kein Kaffee',\n",
              "     'phrase_audio': 'assets/audio/ai/ger/recUA7LJgIjxS3OGI-ger.mp3',\n",
              "     'phrase_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696947300/langdeck/assets/audio/ai/ger/recUA7LJgIjxS3OGI-ger.mp3',\n",
              "     'phrase_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696947286/langdeck/assets/audio/ai/fre/recUA7LJgIjxS3OGI-fre.mp3',\n",
              "     'phrase_related_story_tr': 'Frühstück',\n",
              "     'phrase_notes': '',\n",
              "     'phrase_notes_2': '',\n",
              "     'phrase_notes_translation': '',\n",
              "     'phrase_notes_2_translation': '',\n",
              "     'words': [{'word_language': 'ger',\n",
              "       'word': 'Café',\n",
              "       'word_rec_id': 'recgLzTREq2YHlWn9',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'recgLzTREq2YHlWn9-ger',\n",
              "       'word_translation': 'Kaffee',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/recgLzTREq2YHlWn9-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679468/langdeck/assets/audio/ai/ger/recgLzTREq2YHlWn9-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679456/langdeck/assets/audio/ai/fre/recgLzTREq2YHlWn9-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': 'En France, au petit-déjeuner, on boit surtout du café, avec ou sans lait.',\n",
              "       'word_nutri_notes': 'Le café ne contient presque pas de calories, mais le sucre et la crème qu’on lui ajoute peuvent être très riches. Pour pleinement profiter de ses bienfaits, mieux vaut boire son café noir.',\n",
              "       'word_notes_translation': 'In Frankreich trinken wir zum Frühstück hauptsächlich Kaffee, mit oder ohne Milch.',\n",
              "       'word_nutri_notes_translation': 'Kaffee enthält fast keine Kalorien, aber der zugesetzte Zucker und die Sahne können sehr reichhaltig sein. Um die Vorteile voll auszuschöpfen, ist es besser, Ihren Kaffee schwarz zu trinken.',\n",
              "       'word_tr_rec_id': 'recgLzTREq2YHlWn9-ger',\n",
              "       'keywords': []}]},\n",
              "    {'phrase_language': 'ger',\n",
              "     'phrase_related_story': 'Le petit-déjeuner',\n",
              "     'phrase_related_story_rec_id': 'recYrnBviiGa6SErr',\n",
              "     'phrase_paragraph': '3',\n",
              "     'phrase_position': '3',\n",
              "     'phrase_rec_id': 'recYdPsDVah50TVed',\n",
              "     'phrase': 'Tu veux du thé ?',\n",
              "     'phrase_words': \"['Thé']\",\n",
              "     'phrase_words_rec_id': \"['recHBKIcghkS1g1yr']\",\n",
              "     'phrase_words_tr': \"['Tee']\",\n",
              "     'phrase_words_tr_rec_id': \"['recHBKIcghkS1g1yr-ger']\",\n",
              "     'phrase_html': 'Tu veux du <span id=\"recHBKIcghkS1g1yr\">thé</span> ?',\n",
              "     'phrase_html_rec_id': 'Tu veux du <kw>recHBKIcghkS1g1yr<kw> ?',\n",
              "     'phrase_html_kw': 'Tu veux du <kw>thé<kw> ?',\n",
              "     'phrase_translation': 'Willst du Tee ?',\n",
              "     'phrase_audio': 'assets/audio/ai/ger/recYdPsDVah50TVed-ger.mp3',\n",
              "     'phrase_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1699705974/langdeck/assets/audio/ai/ger/recYdPsDVah50TVed-ger.mp3',\n",
              "     'phrase_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1699705970/langdeck/assets/audio/ai/fre/recYdPsDVah50TVed-fre.mp3',\n",
              "     'phrase_related_story_tr': 'Frühstück',\n",
              "     'phrase_notes': '',\n",
              "     'phrase_notes_2': '',\n",
              "     'phrase_notes_translation': '',\n",
              "     'phrase_notes_2_translation': '',\n",
              "     'words': [{'word_language': 'ger',\n",
              "       'word': 'Thé',\n",
              "       'word_rec_id': 'recHBKIcghkS1g1yr',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'recHBKIcghkS1g1yr-ger',\n",
              "       'word_translation': 'Tee',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/recHBKIcghkS1g1yr-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679476/langdeck/assets/audio/ai/ger/recHBKIcghkS1g1yr-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679465/langdeck/assets/audio/ai/fre/recHBKIcghkS1g1yr-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': '',\n",
              "       'word_nutri_notes': '',\n",
              "       'word_notes_translation': '',\n",
              "       'word_nutri_notes_translation': '',\n",
              "       'word_tr_rec_id': 'recHBKIcghkS1g1yr-ger',\n",
              "       'keywords': []}]},\n",
              "    {'phrase_language': 'ger',\n",
              "     'phrase_related_story': 'Le petit-déjeuner',\n",
              "     'phrase_related_story_rec_id': 'recYrnBviiGa6SErr',\n",
              "     'phrase_paragraph': '4',\n",
              "     'phrase_position': '4',\n",
              "     'phrase_rec_id': 'recfZufpH4ggLyvr1',\n",
              "     'phrase': 'Non merci, pas de thé',\n",
              "     'phrase_words': \"['Thé']\",\n",
              "     'phrase_words_rec_id': \"['recHBKIcghkS1g1yr']\",\n",
              "     'phrase_words_tr': \"['Tee']\",\n",
              "     'phrase_words_tr_rec_id': \"['recHBKIcghkS1g1yr-ger']\",\n",
              "     'phrase_html': 'Non merci, pas de <span id=\"recHBKIcghkS1g1yr\">thé</span>',\n",
              "     'phrase_html_rec_id': 'Non merci, pas de <kw>recHBKIcghkS1g1yr<kw>',\n",
              "     'phrase_html_kw': 'Non merci, pas de <kw>thé<kw>',\n",
              "     'phrase_translation': 'Nein danke, kein Tee',\n",
              "     'phrase_audio': 'assets/audio/ai/ger/recfZufpH4ggLyvr1-ger.mp3',\n",
              "     'phrase_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1699705975/langdeck/assets/audio/ai/ger/recfZufpH4ggLyvr1-ger.mp3',\n",
              "     'phrase_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1699705971/langdeck/assets/audio/ai/fre/recfZufpH4ggLyvr1-fre.mp3',\n",
              "     'phrase_related_story_tr': 'Frühstück',\n",
              "     'phrase_notes': '',\n",
              "     'phrase_notes_2': '',\n",
              "     'phrase_notes_translation': '',\n",
              "     'phrase_notes_2_translation': '',\n",
              "     'words': [{'word_language': 'ger',\n",
              "       'word': 'Thé',\n",
              "       'word_rec_id': 'recHBKIcghkS1g1yr',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'recHBKIcghkS1g1yr-ger',\n",
              "       'word_translation': 'Tee',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/recHBKIcghkS1g1yr-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679476/langdeck/assets/audio/ai/ger/recHBKIcghkS1g1yr-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679465/langdeck/assets/audio/ai/fre/recHBKIcghkS1g1yr-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': '',\n",
              "       'word_nutri_notes': '',\n",
              "       'word_notes_translation': '',\n",
              "       'word_nutri_notes_translation': '',\n",
              "       'word_tr_rec_id': 'recHBKIcghkS1g1yr-ger',\n",
              "       'keywords': []}]},\n",
              "    {'phrase_language': 'ger',\n",
              "     'phrase_related_story': 'Le petit-déjeuner',\n",
              "     'phrase_related_story_rec_id': 'recYrnBviiGa6SErr',\n",
              "     'phrase_paragraph': '5',\n",
              "     'phrase_position': '5',\n",
              "     'phrase_rec_id': 'recTAFl7XLOpY2uF8',\n",
              "     'phrase': 'Tu préfères un verre de lait ?',\n",
              "     'phrase_words': \"['Préférer', 'Verre', 'Lait']\",\n",
              "     'phrase_words_rec_id': \"['recjrYmMQwRgvVtHW', 'rec2uNVme8oXFMxsB', 'rec828nPZgEYyy3OS']\",\n",
              "     'phrase_words_tr': \"['Bevorzugen', 'Glas', 'Milch']\",\n",
              "     'phrase_words_tr_rec_id': \"['recjrYmMQwRgvVtHW-ger', 'rec2uNVme8oXFMxsB-ger', 'rec828nPZgEYyy3OS-ger']\",\n",
              "     'phrase_html': 'Tu <span id=\"recjrYmMQwRgvVtHW\">préfères</span> un <span id=\"rec2uNVme8oXFMxsB\">verre</span> de <span id=\"rec828nPZgEYyy3OS\">lait</span> ?',\n",
              "     'phrase_html_rec_id': 'Tu <kw>recjrYmMQwRgvVtHW<kw> un <kw>rec2uNVme8oXFMxsB<kw> de <kw>rec828nPZgEYyy3OS<kw> ?',\n",
              "     'phrase_html_kw': 'Tu <kw>préfères<kw> un <kw>verre<kw> de <kw>lait<kw> ?',\n",
              "     'phrase_translation': 'Möchten Sie lieber ein Glas Milch?',\n",
              "     'phrase_audio': 'assets/audio/ai/ger/recTAFl7XLOpY2uF8-ger.mp3',\n",
              "     'phrase_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1699705975/langdeck/assets/audio/ai/ger/recTAFl7XLOpY2uF8-ger.mp3',\n",
              "     'phrase_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1699705971/langdeck/assets/audio/ai/fre/recTAFl7XLOpY2uF8-fre.mp3',\n",
              "     'phrase_related_story_tr': 'Frühstück',\n",
              "     'phrase_notes': \"Notez la différence entre les accents. Pour l'instant, retenez seulement que é se prononce comme dans le mot thé et è se prononce comme dans le mot lait.\",\n",
              "     'phrase_notes_2': '',\n",
              "     'phrase_notes_translation': 'Beachten Sie den Unterschied zwischen den Akzenten. Denken Sie vorerst daran, dass é wie im Wort „Tee“ und è wie im Wort „Milch“ ausgesprochen wird.',\n",
              "     'phrase_notes_2_translation': '',\n",
              "     'words': [{'word_language': 'ger',\n",
              "       'word': 'Préférer',\n",
              "       'word_rec_id': 'recjrYmMQwRgvVtHW',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'recjrYmMQwRgvVtHW-ger',\n",
              "       'word_translation': 'Bevorzugen',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/recjrYmMQwRgvVtHW-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696866662/langdeck/assets/audio/ai/ger/recjrYmMQwRgvVtHW-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696866659/langdeck/assets/audio/ai/fre/recjrYmMQwRgvVtHW-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': '',\n",
              "       'word_nutri_notes': '',\n",
              "       'word_notes_translation': '',\n",
              "       'word_nutri_notes_translation': '',\n",
              "       'word_tr_rec_id': 'recjrYmMQwRgvVtHW-ger',\n",
              "       'keywords': []},\n",
              "      {'word_language': 'ger',\n",
              "       'word': 'Verre',\n",
              "       'word_rec_id': 'rec2uNVme8oXFMxsB',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'rec2uNVme8oXFMxsB-ger',\n",
              "       'word_translation': 'Glas',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/rec2uNVme8oXFMxsB-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679477/langdeck/assets/audio/ai/ger/rec2uNVme8oXFMxsB-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679465/langdeck/assets/audio/ai/fre/rec2uNVme8oXFMxsB-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': '',\n",
              "       'word_nutri_notes': '',\n",
              "       'word_notes_translation': '',\n",
              "       'word_nutri_notes_translation': '',\n",
              "       'word_tr_rec_id': 'rec2uNVme8oXFMxsB-ger',\n",
              "       'keywords': []},\n",
              "      {'word_language': 'ger',\n",
              "       'word': 'Lait',\n",
              "       'word_rec_id': 'rec828nPZgEYyy3OS',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'rec828nPZgEYyy3OS-ger',\n",
              "       'word_translation': 'Milch',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/rec828nPZgEYyy3OS-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679473/langdeck/assets/audio/ai/ger/rec828nPZgEYyy3OS-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679461/langdeck/assets/audio/ai/fre/rec828nPZgEYyy3OS-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': '',\n",
              "       'word_nutri_notes': '',\n",
              "       'word_notes_translation': '',\n",
              "       'word_nutri_notes_translation': '',\n",
              "       'word_tr_rec_id': 'rec828nPZgEYyy3OS-ger',\n",
              "       'keywords': []}]},\n",
              "    {'phrase_language': 'ger',\n",
              "     'phrase_related_story': 'Le petit-déjeuner',\n",
              "     'phrase_related_story_rec_id': 'recYrnBviiGa6SErr',\n",
              "     'phrase_paragraph': '6',\n",
              "     'phrase_position': '6',\n",
              "     'phrase_rec_id': 'reczV4nmMx5SMRpub',\n",
              "     'phrase': \"Je veux bien du jus de fruit, s'il te plait\",\n",
              "     'phrase_words': \"['Jus de fruit']\",\n",
              "     'phrase_words_rec_id': \"['rect8hj7MI7YIXGAl']\",\n",
              "     'phrase_words_tr': \"['Fruchtsaft']\",\n",
              "     'phrase_words_tr_rec_id': \"['rect8hj7MI7YIXGAl-ger']\",\n",
              "     'phrase_html': 'Je veux bien du <span id=\"rect8hj7MI7YIXGAl\">jus de fruit,</span> s\\'il te plait',\n",
              "     'phrase_html_rec_id': \"Je veux bien du <kw>rect8hj7MI7YIXGAl<kw> s'il te plait\",\n",
              "     'phrase_html_kw': \"Je veux bien du <kw>jus de fruit,<kw> s'il te plait\",\n",
              "     'phrase_translation': 'Ich hätte gerne etwas Fruchtsaft, bitte',\n",
              "     'phrase_audio': 'assets/audio/ai/ger/reczV4nmMx5SMRpub-ger.mp3',\n",
              "     'phrase_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1699948082/langdeck/assets/audio/ai/ger/reczV4nmMx5SMRpub-ger.mp3',\n",
              "     'phrase_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1700043636/langdeck/assets/audio/ai/fre/reczV4nmMx5SMRpub-fre.mp3',\n",
              "     'phrase_related_story_tr': 'Frühstück',\n",
              "     'phrase_notes': '',\n",
              "     'phrase_notes_2': '',\n",
              "     'phrase_notes_translation': '',\n",
              "     'phrase_notes_2_translation': '',\n",
              "     'words': [{'word_language': 'ger',\n",
              "       'word': 'Jus de fruit',\n",
              "       'word_rec_id': 'rect8hj7MI7YIXGAl',\n",
              "       'order': 2,\n",
              "       'word_type': 'Expression',\n",
              "       'word_translation_id': 'rect8hj7MI7YIXGAl-ger',\n",
              "       'word_translation': 'Fruchtsaft',\n",
              "       'word_lemmas': \"['Jus', 'Fruit']\",\n",
              "       'word_lemmas_rec_id': \"['rec5rbfb20TFOpn5s', 'recxMserKVL7AnVFh']\",\n",
              "       'word_audio': 'assets/audio/ai/ger/rect8hj7MI7YIXGAl-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679473/langdeck/assets/audio/ai/ger/rect8hj7MI7YIXGAl-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679460/langdeck/assets/audio/ai/fre/rect8hj7MI7YIXGAl-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': \"['rec5rbfb20TFOpn5s-ger', 'recxMserKVL7AnVFh-ger']\",\n",
              "       'word_lemmas_tr': \"['Saft', 'Obst']\",\n",
              "       'word_notes': '',\n",
              "       'word_nutri_notes': '',\n",
              "       'word_notes_translation': '',\n",
              "       'word_nutri_notes_translation': '',\n",
              "       'word_tr_rec_id': 'rect8hj7MI7YIXGAl-ger',\n",
              "       'keywords': [{'word_language': 'ger',\n",
              "         'word': 'Jus',\n",
              "         'word_rec_id': 'rec5rbfb20TFOpn5s',\n",
              "         'order': 1,\n",
              "         'word_type': 'Lemma',\n",
              "         'word_translation_id': 'rec5rbfb20TFOpn5s-ger',\n",
              "         'word_translation': 'Saft',\n",
              "         'word_lemmas': '',\n",
              "         'word_lemmas_rec_id': '',\n",
              "         'word_audio': 'assets/audio/ai/ger/rec5rbfb20TFOpn5s-ger.mp3',\n",
              "         'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679471/langdeck/assets/audio/ai/ger/rec5rbfb20TFOpn5s-ger.mp3',\n",
              "         'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679459/langdeck/assets/audio/ai/fre/rec5rbfb20TFOpn5s-fre.mp3',\n",
              "         'word_lemmas_tr_rec_id': '',\n",
              "         'word_lemmas_tr': '',\n",
              "         'word_notes': '',\n",
              "         'word_nutri_notes': '',\n",
              "         'word_notes_translation': '',\n",
              "         'word_nutri_notes_translation': '',\n",
              "         'keyword': 'rec5rbfb20TFOpn5s'},\n",
              "        {'word_language': 'ger',\n",
              "         'word': 'Fruit',\n",
              "         'word_rec_id': 'recxMserKVL7AnVFh',\n",
              "         'order': 1,\n",
              "         'word_type': 'Lemma',\n",
              "         'word_translation_id': 'recxMserKVL7AnVFh-ger',\n",
              "         'word_translation': 'Obst',\n",
              "         'word_lemmas': '',\n",
              "         'word_lemmas_rec_id': '',\n",
              "         'word_audio': 'assets/audio/ai/ger/recxMserKVL7AnVFh-ger.mp3',\n",
              "         'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679471/langdeck/assets/audio/ai/ger/recxMserKVL7AnVFh-ger.mp3',\n",
              "         'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679458/langdeck/assets/audio/ai/fre/recxMserKVL7AnVFh-fre.mp3',\n",
              "         'word_lemmas_tr_rec_id': '',\n",
              "         'word_lemmas_tr': '',\n",
              "         'word_notes': '',\n",
              "         'word_nutri_notes': '',\n",
              "         'word_notes_translation': '',\n",
              "         'word_nutri_notes_translation': '',\n",
              "         'keyword': 'recxMserKVL7AnVFh'}]}]},\n",
              "    {'phrase_language': 'ger',\n",
              "     'phrase_related_story': 'Le petit-déjeuner',\n",
              "     'phrase_related_story_rec_id': 'recYrnBviiGa6SErr',\n",
              "     'phrase_paragraph': '7',\n",
              "     'phrase_position': '7',\n",
              "     'phrase_rec_id': 'recxzZPbQkLXRT59s',\n",
              "     'phrase': \"Voici un verre de jus d'orange\",\n",
              "     'phrase_words': '[\\'Verre\\', \"Jus d\\'orange\"]',\n",
              "     'phrase_words_rec_id': \"['rec2uNVme8oXFMxsB', 'receNtWmFuccPjgYU']\",\n",
              "     'phrase_words_tr': \"['Glas', 'Orangensaft']\",\n",
              "     'phrase_words_tr_rec_id': \"['rec2uNVme8oXFMxsB-ger', 'receNtWmFuccPjgYU-ger']\",\n",
              "     'phrase_html': 'Voici un <span id=\"rec2uNVme8oXFMxsB\">verre</span> de <span id=\"receNtWmFuccPjgYU\">jus d\\'orange</span>',\n",
              "     'phrase_html_rec_id': 'Voici un <kw>rec2uNVme8oXFMxsB<kw> de <kw>receNtWmFuccPjgYU<kw>',\n",
              "     'phrase_html_kw': \"Voici un <kw>verre<kw> de <kw>jus d'orange<kw>\",\n",
              "     'phrase_translation': 'Hier ist ein Glas Orangensaft',\n",
              "     'phrase_audio': 'assets/audio/ai/ger/recxzZPbQkLXRT59s-ger.mp3',\n",
              "     'phrase_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1699705977/langdeck/assets/audio/ai/ger/recxzZPbQkLXRT59s-ger.mp3',\n",
              "     'phrase_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1699705973/langdeck/assets/audio/ai/fre/recxzZPbQkLXRT59s-fre.mp3',\n",
              "     'phrase_related_story_tr': 'Frühstück',\n",
              "     'phrase_notes': '',\n",
              "     'phrase_notes_2': '',\n",
              "     'phrase_notes_translation': '',\n",
              "     'phrase_notes_2_translation': '',\n",
              "     'words': [{'word_language': 'ger',\n",
              "       'word': 'Verre',\n",
              "       'word_rec_id': 'rec2uNVme8oXFMxsB',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'rec2uNVme8oXFMxsB-ger',\n",
              "       'word_translation': 'Glas',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/rec2uNVme8oXFMxsB-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679477/langdeck/assets/audio/ai/ger/rec2uNVme8oXFMxsB-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679465/langdeck/assets/audio/ai/fre/rec2uNVme8oXFMxsB-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': '',\n",
              "       'word_nutri_notes': '',\n",
              "       'word_notes_translation': '',\n",
              "       'word_nutri_notes_translation': '',\n",
              "       'word_tr_rec_id': 'rec2uNVme8oXFMxsB-ger',\n",
              "       'keywords': []},\n",
              "      {'word_language': 'ger',\n",
              "       'word': \"Jus d'orange\",\n",
              "       'word_rec_id': 'receNtWmFuccPjgYU',\n",
              "       'order': 2,\n",
              "       'word_type': 'Expression',\n",
              "       'word_translation_id': 'receNtWmFuccPjgYU-ger',\n",
              "       'word_translation': 'Orangensaft',\n",
              "       'word_lemmas': \"['Jus', 'Orange']\",\n",
              "       'word_lemmas_rec_id': \"['rec5rbfb20TFOpn5s', 'rechRvQixgB1N3337']\",\n",
              "       'word_audio': 'assets/audio/ai/ger/receNtWmFuccPjgYU-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679472/langdeck/assets/audio/ai/ger/receNtWmFuccPjgYU-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679460/langdeck/assets/audio/ai/fre/receNtWmFuccPjgYU-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': \"['rec5rbfb20TFOpn5s-ger', 'rechRvQixgB1N3337-ger']\",\n",
              "       'word_lemmas_tr': \"['Saft', 'Orange']\",\n",
              "       'word_notes': '',\n",
              "       'word_nutri_notes': '',\n",
              "       'word_notes_translation': '',\n",
              "       'word_nutri_notes_translation': '',\n",
              "       'word_tr_rec_id': 'receNtWmFuccPjgYU-ger',\n",
              "       'keywords': [{'word_language': 'ger',\n",
              "         'word': 'Jus',\n",
              "         'word_rec_id': 'rec5rbfb20TFOpn5s',\n",
              "         'order': 1,\n",
              "         'word_type': 'Lemma',\n",
              "         'word_translation_id': 'rec5rbfb20TFOpn5s-ger',\n",
              "         'word_translation': 'Saft',\n",
              "         'word_lemmas': '',\n",
              "         'word_lemmas_rec_id': '',\n",
              "         'word_audio': 'assets/audio/ai/ger/rec5rbfb20TFOpn5s-ger.mp3',\n",
              "         'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679471/langdeck/assets/audio/ai/ger/rec5rbfb20TFOpn5s-ger.mp3',\n",
              "         'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679459/langdeck/assets/audio/ai/fre/rec5rbfb20TFOpn5s-fre.mp3',\n",
              "         'word_lemmas_tr_rec_id': '',\n",
              "         'word_lemmas_tr': '',\n",
              "         'word_notes': '',\n",
              "         'word_nutri_notes': '',\n",
              "         'word_notes_translation': '',\n",
              "         'word_nutri_notes_translation': '',\n",
              "         'keyword': 'rec5rbfb20TFOpn5s'},\n",
              "        {'word_language': 'ger',\n",
              "         'word': 'Orange',\n",
              "         'word_rec_id': 'rechRvQixgB1N3337',\n",
              "         'order': 1,\n",
              "         'word_type': 'Lemma',\n",
              "         'word_translation_id': 'rechRvQixgB1N3337-ger',\n",
              "         'word_translation': 'Orange',\n",
              "         'word_lemmas': '',\n",
              "         'word_lemmas_rec_id': '',\n",
              "         'word_audio': 'assets/audio/ai/ger/rechRvQixgB1N3337-ger.mp3',\n",
              "         'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679474/langdeck/assets/audio/ai/ger/rechRvQixgB1N3337-ger.mp3',\n",
              "         'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679463/langdeck/assets/audio/ai/fre/rechRvQixgB1N3337-fre.mp3',\n",
              "         'word_lemmas_tr_rec_id': '',\n",
              "         'word_lemmas_tr': '',\n",
              "         'word_notes': '',\n",
              "         'word_nutri_notes': '',\n",
              "         'word_notes_translation': '',\n",
              "         'word_nutri_notes_translation': '',\n",
              "         'keyword': 'rechRvQixgB1N3337'}]}]},\n",
              "    {'phrase_language': 'ger',\n",
              "     'phrase_related_story': 'Le petit-déjeuner',\n",
              "     'phrase_related_story_rec_id': 'recYrnBviiGa6SErr',\n",
              "     'phrase_paragraph': '8',\n",
              "     'phrase_position': '8',\n",
              "     'phrase_rec_id': 'recikNugTazJrLLVE',\n",
              "     'phrase': 'Super ! Merci',\n",
              "     'phrase_words': \"['Super']\",\n",
              "     'phrase_words_rec_id': \"['recVyn4uxhrR2JuNa']\",\n",
              "     'phrase_words_tr': \"['Großartig']\",\n",
              "     'phrase_words_tr_rec_id': \"['recVyn4uxhrR2JuNa-ger']\",\n",
              "     'phrase_html': 'Super ! Merci',\n",
              "     'phrase_html_rec_id': 'Super ! Merci',\n",
              "     'phrase_html_kw': 'Super ! Merci',\n",
              "     'phrase_translation': 'Großartig ! DANKE',\n",
              "     'phrase_audio': 'assets/audio/ai/ger/recikNugTazJrLLVE-ger.mp3',\n",
              "     'phrase_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696947307/langdeck/assets/audio/ai/ger/recikNugTazJrLLVE-ger.mp3',\n",
              "     'phrase_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696947291/langdeck/assets/audio/ai/fre/recikNugTazJrLLVE-fre.mp3',\n",
              "     'phrase_related_story_tr': 'Frühstück',\n",
              "     'phrase_notes': '',\n",
              "     'phrase_notes_2': '',\n",
              "     'phrase_notes_translation': '',\n",
              "     'phrase_notes_2_translation': '',\n",
              "     'words': [{'word_language': 'ger',\n",
              "       'word': 'Super',\n",
              "       'word_rec_id': 'recVyn4uxhrR2JuNa',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'recVyn4uxhrR2JuNa-ger',\n",
              "       'word_translation': 'Großartig',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/recVyn4uxhrR2JuNa-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1700130230/langdeck/assets/audio/ai/ger/recVyn4uxhrR2JuNa-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1700130230/langdeck/assets/audio/ai/fre/recVyn4uxhrR2JuNa-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': 'Interjection. Expression familière pour marquer sa joie, sa satisfaction.',\n",
              "       'word_nutri_notes': '',\n",
              "       'word_notes_translation': 'Zwischenruf. Vertrauter Ausdruck, um Freude und Zufriedenheit auszudrücken.',\n",
              "       'word_nutri_notes_translation': '',\n",
              "       'word_tr_rec_id': 'recVyn4uxhrR2JuNa-ger',\n",
              "       'keywords': []}]}]},\n",
              "  {'story': 'Le petit-déjeuner (suite)',\n",
              "   'story_rec_id': 'rec2XfSwLVFBBiHj7',\n",
              "   'story_translation_id': 'rec2XfSwLVFBBiHj7-ger',\n",
              "   'story_name': 'Le petit-déjeuner (suite)',\n",
              "   'story_translation': 'Frühstück (Fortsetzung)',\n",
              "   'story_level': 'Beginner',\n",
              "   'story_episode': 'Part 2',\n",
              "   'story_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1700041122/langdeck/assets/audio/ai/ger/rec2XfSwLVFBBiHj7-ger.mp3',\n",
              "   'story_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1700041122/langdeck/assets/audio/ai/fre/rec2XfSwLVFBBiHj7-fre.mp3',\n",
              "   'story_illustration': 'https://res.cloudinary.com/dhc7ovnwk/image/upload/v1698074882/langdeck/assets/images/saynetes/fdrquegyt56djolu1uc2.jpg',\n",
              "   'story_desc': \"Une leçon de niveau facile pour débuter. Démarrons la journée par un petit-déjeuner pour apprendre les premiers mots et quelques règles simples de l'usage du français dans la vie courante.\",\n",
              "   'story_desc_translation': 'Eine einfache Lektion für den Anfang. Beginnen wir den Tag mit einem Frühstück, um die ersten Wörter und einige einfache Regeln für die Verwendung der französischen Sprache im Alltag zu lernen.',\n",
              "   'phrases': [{'phrase_language': 'ger',\n",
              "     'phrase_related_story': 'Le petit-déjeuner (suite)',\n",
              "     'phrase_related_story_rec_id': 'rec2XfSwLVFBBiHj7',\n",
              "     'phrase_paragraph': '1',\n",
              "     'phrase_position': '1',\n",
              "     'phrase_rec_id': 'rec79hnLWCBTRFdMs',\n",
              "     'phrase': 'Tu veux du pain ou un bol de céréales ?',\n",
              "     'phrase_words': \"['Pain', 'Bol de céréales']\",\n",
              "     'phrase_words_rec_id': \"['recpFeoCwi15UyOe3', 'recdsQ1ThzPmnsxRY']\",\n",
              "     'phrase_words_tr': \"['Brot', 'Schüssel Müsli']\",\n",
              "     'phrase_words_tr_rec_id': \"['recpFeoCwi15UyOe3-ger', 'recdsQ1ThzPmnsxRY-ger']\",\n",
              "     'phrase_html': 'Tu veux du <span id=\"recpFeoCwi15UyOe3\">pain</span> ou un <span id=\"recdsQ1ThzPmnsxRY\">bol de céréales</span> ?',\n",
              "     'phrase_html_rec_id': 'Tu veux du <kw>recpFeoCwi15UyOe3<kw> ou un <kw>recdsQ1ThzPmnsxRY<kw> ?',\n",
              "     'phrase_html_kw': 'Tu veux du <kw>pain<kw> ou un <kw>bol de céréales<kw> ?',\n",
              "     'phrase_translation': 'Möchten Sie etwas Brot oder eine Schüssel Müsli?',\n",
              "     'phrase_audio': 'assets/audio/ai/ger/rec79hnLWCBTRFdMs-ger.mp3',\n",
              "     'phrase_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696947307/langdeck/assets/audio/ai/ger/rec79hnLWCBTRFdMs-ger.mp3',\n",
              "     'phrase_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696947292/langdeck/assets/audio/ai/fre/rec79hnLWCBTRFdMs-fre.mp3',\n",
              "     'phrase_related_story_tr': 'Frühstück (Fortsetzung)',\n",
              "     'phrase_notes': '',\n",
              "     'phrase_notes_2': '',\n",
              "     'phrase_notes_translation': '',\n",
              "     'phrase_notes_2_translation': '',\n",
              "     'words': [{'word_language': 'ger',\n",
              "       'word': 'Pain',\n",
              "       'word_rec_id': 'recpFeoCwi15UyOe3',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'recpFeoCwi15UyOe3-ger',\n",
              "       'word_translation': 'Brot',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/recpFeoCwi15UyOe3-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679475/langdeck/assets/audio/ai/ger/recpFeoCwi15UyOe3-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679463/langdeck/assets/audio/ai/fre/recpFeoCwi15UyOe3-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': 'Véritable emblème de la culture française, le pain se décline sous de multiples formes. ',\n",
              "       'word_nutri_notes': \"Les teneurs en matières grasses, protéines et glucides sont relativement semblables entre les différentes variétés de pain. Les teneurs en fibres, en vitamines et en minéraux sont toutefois différentes d’un pain à l’autre et dépendent surtout de la farine utilisée. Le pain complet est à privilégier car il est riche en nutriments et permet d'aider à la gestion du poids.\",\n",
              "       'word_notes_translation': 'Brot ist ein wahres Symbol der französischen Kultur und gibt es in vielen Formen.',\n",
              "       'word_nutri_notes_translation': 'Der Fett-, Protein- und Kohlenhydratgehalt ist bei verschiedenen Brotsorten relativ ähnlich. Allerdings variieren die Ballaststoff-, Vitamin- und Mineralstoffgehalte von Brot zu Brot und hängen vor allem vom verwendeten Mehl ab. Vollkornbrot wird bevorzugt, da es reich an Nährstoffen ist und beim Gewichtsmanagement hilft.',\n",
              "       'word_tr_rec_id': 'recpFeoCwi15UyOe3-ger',\n",
              "       'keywords': []},\n",
              "      {'word_language': 'ger',\n",
              "       'word': 'Bol de céréales',\n",
              "       'word_rec_id': 'recdsQ1ThzPmnsxRY',\n",
              "       'order': 2,\n",
              "       'word_type': 'Expression',\n",
              "       'word_translation_id': 'recdsQ1ThzPmnsxRY-ger',\n",
              "       'word_translation': 'Schüssel Müsli',\n",
              "       'word_lemmas': \"['Céréales']\",\n",
              "       'word_lemmas_rec_id': \"['recd1mpIAP1zIshsC']\",\n",
              "       'word_audio': 'assets/audio/ai/ger/recdsQ1ThzPmnsxRY-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679467/langdeck/assets/audio/ai/ger/recdsQ1ThzPmnsxRY-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679455/langdeck/assets/audio/ai/fre/recdsQ1ThzPmnsxRY-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': \"['recd1mpIAP1zIshsC-ger']\",\n",
              "       'word_lemmas_tr': \"['Getreide']\",\n",
              "       'word_notes': '',\n",
              "       'word_nutri_notes': '',\n",
              "       'word_notes_translation': '',\n",
              "       'word_nutri_notes_translation': '',\n",
              "       'word_tr_rec_id': 'recdsQ1ThzPmnsxRY-ger',\n",
              "       'keywords': [{'word_language': 'ger',\n",
              "         'word': 'Céréales',\n",
              "         'word_rec_id': 'recd1mpIAP1zIshsC',\n",
              "         'order': 1,\n",
              "         'word_type': 'Lemma',\n",
              "         'word_translation_id': 'recd1mpIAP1zIshsC-ger',\n",
              "         'word_translation': 'Getreide',\n",
              "         'word_lemmas': '',\n",
              "         'word_lemmas_rec_id': '',\n",
              "         'word_audio': 'assets/audio/ai/ger/recd1mpIAP1zIshsC-ger.mp3',\n",
              "         'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679469/langdeck/assets/audio/ai/ger/recd1mpIAP1zIshsC-ger.mp3',\n",
              "         'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679457/langdeck/assets/audio/ai/fre/recd1mpIAP1zIshsC-fre.mp3',\n",
              "         'word_lemmas_tr_rec_id': '',\n",
              "         'word_lemmas_tr': '',\n",
              "         'word_notes': '',\n",
              "         'word_nutri_notes': '',\n",
              "         'word_notes_translation': '',\n",
              "         'word_nutri_notes_translation': '',\n",
              "         'keyword': 'recd1mpIAP1zIshsC'}]}]},\n",
              "    {'phrase_language': 'ger',\n",
              "     'phrase_related_story': 'Le petit-déjeuner (suite)',\n",
              "     'phrase_related_story_rec_id': 'rec2XfSwLVFBBiHj7',\n",
              "     'phrase_paragraph': '2',\n",
              "     'phrase_position': '2',\n",
              "     'phrase_rec_id': 'recpAU9fi9gQyq77C',\n",
              "     'phrase': 'Je veux bien du pain avec du beurre et de la confiture',\n",
              "     'phrase_words': \"['Pain', 'Beurre', 'Confiture']\",\n",
              "     'phrase_words_rec_id': \"['recpFeoCwi15UyOe3', 'recroMWe3PJCSMVIq', 'reccrviLRZ5rhpjqf']\",\n",
              "     'phrase_words_tr': \"['Brot', 'Butter', 'Marmelade']\",\n",
              "     'phrase_words_tr_rec_id': \"['recpFeoCwi15UyOe3-ger', 'recroMWe3PJCSMVIq-ger', 'reccrviLRZ5rhpjqf-ger']\",\n",
              "     'phrase_html': 'Je veux bien du <span id=\"recpFeoCwi15UyOe3\">pain</span> avec du <span id=\"recroMWe3PJCSMVIq\">beurre</span> et de la <span id=\"reccrviLRZ5rhpjqf\">confiture</span>',\n",
              "     'phrase_html_rec_id': 'Je veux bien du <kw>recpFeoCwi15UyOe3<kw> avec du <kw>recroMWe3PJCSMVIq<kw> et de la <kw>reccrviLRZ5rhpjqf<kw>',\n",
              "     'phrase_html_kw': 'Je veux bien du <kw>pain<kw> avec du <kw>beurre<kw> et de la <kw>confiture<kw>',\n",
              "     'phrase_translation': 'Ich hätte gerne etwas Brot mit Butter und Marmelade',\n",
              "     'phrase_audio': 'assets/audio/ai/ger/recpAU9fi9gQyq77C-ger.mp3',\n",
              "     'phrase_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1697635327/langdeck/assets/audio/ai/ger/recpAU9fi9gQyq77C-ger.mp3',\n",
              "     'phrase_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1697634758/langdeck/assets/audio/ai/fre/recpAU9fi9gQyq77C-fre.mp3',\n",
              "     'phrase_related_story_tr': 'Frühstück (Fortsetzung)',\n",
              "     'phrase_notes': '',\n",
              "     'phrase_notes_2': '',\n",
              "     'phrase_notes_translation': '',\n",
              "     'phrase_notes_2_translation': '',\n",
              "     'words': [{'word_language': 'ger',\n",
              "       'word': 'Pain',\n",
              "       'word_rec_id': 'recpFeoCwi15UyOe3',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'recpFeoCwi15UyOe3-ger',\n",
              "       'word_translation': 'Brot',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/recpFeoCwi15UyOe3-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679475/langdeck/assets/audio/ai/ger/recpFeoCwi15UyOe3-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679463/langdeck/assets/audio/ai/fre/recpFeoCwi15UyOe3-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': 'Véritable emblème de la culture française, le pain se décline sous de multiples formes. ',\n",
              "       'word_nutri_notes': \"Les teneurs en matières grasses, protéines et glucides sont relativement semblables entre les différentes variétés de pain. Les teneurs en fibres, en vitamines et en minéraux sont toutefois différentes d’un pain à l’autre et dépendent surtout de la farine utilisée. Le pain complet est à privilégier car il est riche en nutriments et permet d'aider à la gestion du poids.\",\n",
              "       'word_notes_translation': 'Brot ist ein wahres Symbol der französischen Kultur und gibt es in vielen Formen.',\n",
              "       'word_nutri_notes_translation': 'Der Fett-, Protein- und Kohlenhydratgehalt ist bei verschiedenen Brotsorten relativ ähnlich. Allerdings variieren die Ballaststoff-, Vitamin- und Mineralstoffgehalte von Brot zu Brot und hängen vor allem vom verwendeten Mehl ab. Vollkornbrot wird bevorzugt, da es reich an Nährstoffen ist und beim Gewichtsmanagement hilft.',\n",
              "       'word_tr_rec_id': 'recpFeoCwi15UyOe3-ger',\n",
              "       'keywords': []},\n",
              "      {'word_language': 'ger',\n",
              "       'word': 'Beurre',\n",
              "       'word_rec_id': 'recroMWe3PJCSMVIq',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'recroMWe3PJCSMVIq-ger',\n",
              "       'word_translation': 'Butter',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/recroMWe3PJCSMVIq-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679466/langdeck/assets/audio/ai/ger/recroMWe3PJCSMVIq-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679454/langdeck/assets/audio/ai/fre/recroMWe3PJCSMVIq-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': '',\n",
              "       'word_nutri_notes': '',\n",
              "       'word_notes_translation': '',\n",
              "       'word_nutri_notes_translation': '',\n",
              "       'word_tr_rec_id': 'recroMWe3PJCSMVIq-ger',\n",
              "       'keywords': []},\n",
              "      {'word_language': 'ger',\n",
              "       'word': 'Confiture',\n",
              "       'word_rec_id': 'reccrviLRZ5rhpjqf',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'reccrviLRZ5rhpjqf-ger',\n",
              "       'word_translation': 'Marmelade',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/reccrviLRZ5rhpjqf-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679470/langdeck/assets/audio/ai/ger/reccrviLRZ5rhpjqf-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679457/langdeck/assets/audio/ai/fre/reccrviLRZ5rhpjqf-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': '',\n",
              "       'word_nutri_notes': '',\n",
              "       'word_notes_translation': '',\n",
              "       'word_nutri_notes_translation': '',\n",
              "       'word_tr_rec_id': 'reccrviLRZ5rhpjqf-ger',\n",
              "       'keywords': []}]},\n",
              "    {'phrase_language': 'ger',\n",
              "     'phrase_related_story': 'Le petit-déjeuner (suite)',\n",
              "     'phrase_related_story_rec_id': 'rec2XfSwLVFBBiHj7',\n",
              "     'phrase_paragraph': '3',\n",
              "     'phrase_position': '3',\n",
              "     'phrase_rec_id': 'recF1VeoSgj59xmnf',\n",
              "     'phrase': 'Tu veux du fromage ?',\n",
              "     'phrase_words': \"['Fromage']\",\n",
              "     'phrase_words_rec_id': \"['recoUyEv4BuTkl2Jy']\",\n",
              "     'phrase_words_tr': \"['Käse']\",\n",
              "     'phrase_words_tr_rec_id': \"['recoUyEv4BuTkl2Jy-ger']\",\n",
              "     'phrase_html': 'Tu veux du <span id=\"recoUyEv4BuTkl2Jy\">fromage</span> ?',\n",
              "     'phrase_html_rec_id': 'Tu veux du <kw>recoUyEv4BuTkl2Jy<kw> ?',\n",
              "     'phrase_html_kw': 'Tu veux du <kw>fromage<kw> ?',\n",
              "     'phrase_translation': 'Willst du etwas Käse?',\n",
              "     'phrase_audio': 'assets/audio/ai/ger/recF1VeoSgj59xmnf-ger.mp3',\n",
              "     'phrase_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696947309/langdeck/assets/audio/ai/ger/recF1VeoSgj59xmnf-ger.mp3',\n",
              "     'phrase_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696947294/langdeck/assets/audio/ai/fre/recF1VeoSgj59xmnf-fre.mp3',\n",
              "     'phrase_related_story_tr': 'Frühstück (Fortsetzung)',\n",
              "     'phrase_notes': '',\n",
              "     'phrase_notes_2': '',\n",
              "     'phrase_notes_translation': '',\n",
              "     'phrase_notes_2_translation': '',\n",
              "     'words': [{'word_language': 'ger',\n",
              "       'word': 'Fromage',\n",
              "       'word_rec_id': 'recoUyEv4BuTkl2Jy',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'recoUyEv4BuTkl2Jy-ger',\n",
              "       'word_translation': 'Käse',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/recoUyEv4BuTkl2Jy-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679470/langdeck/assets/audio/ai/ger/recoUyEv4BuTkl2Jy-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679458/langdeck/assets/audio/ai/fre/recoUyEv4BuTkl2Jy-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': 'Le fromage est avant tout une fermentation du lait activée par des bactéries lactiques. Il en existe des centaines de types à travers le monde et la France en compte au moins 400. Il se consomme seul ou entre dans la préparation de nombreux plats.',\n",
              "       'word_nutri_notes': 'Le fromage est un aliment calorique en totalisant 338 Cal/100 g, essentiellement dû à ses lipides. C’est un bon fournisseur de protéines, de calcium, de phosphore, de vitamine A et de zinc.\\nLe fromage n’est pas à bannir de l’alimentation car il est riche de bienfaits sur le plan nutritionnel.',\n",
              "       'word_notes_translation': 'Käse ist vor allem eine durch Milchsäurebakterien aktivierte Fermentation von Milch. Weltweit gibt es Hunderte von Arten, in Frankreich gibt es mindestens 400. Man verzehrt sie allein oder verwendet sie für die Zubereitung vieler Gerichte.',\n",
              "       'word_nutri_notes_translation': 'Käse ist ein kalorienreiches Lebensmittel mit insgesamt 338 Kalorien pro 100 g, vor allem aufgrund seiner Lipide. Es ist ein guter Lieferant von Eiweiß, Kalzium, Phosphor, Vitamin A und Zink.\\nKäse sollte nicht vom Speiseplan verbannt werden, da er reich an ernährungsphysiologischen Vorteilen ist.',\n",
              "       'word_tr_rec_id': 'recoUyEv4BuTkl2Jy-ger',\n",
              "       'keywords': []}]},\n",
              "    {'phrase_language': 'ger',\n",
              "     'phrase_related_story': 'Le petit-déjeuner (suite)',\n",
              "     'phrase_related_story_rec_id': 'rec2XfSwLVFBBiHj7',\n",
              "     'phrase_paragraph': '4',\n",
              "     'phrase_position': '4',\n",
              "     'phrase_rec_id': 'reciTOL2fmbj9noVi',\n",
              "     'phrase': \"Non merci, je n'aime pas le fromage\",\n",
              "     'phrase_words': \"['Fromage']\",\n",
              "     'phrase_words_rec_id': \"['recoUyEv4BuTkl2Jy']\",\n",
              "     'phrase_words_tr': \"['Käse']\",\n",
              "     'phrase_words_tr_rec_id': \"['recoUyEv4BuTkl2Jy-ger']\",\n",
              "     'phrase_html': 'Non merci, je n\\'aime pas le <span id=\"recoUyEv4BuTkl2Jy\">fromage</span>',\n",
              "     'phrase_html_rec_id': \"Non merci, je n'aime pas le <kw>recoUyEv4BuTkl2Jy<kw>\",\n",
              "     'phrase_html_kw': \"Non merci, je n'aime pas le <kw>fromage<kw>\",\n",
              "     'phrase_translation': 'Nein danke, ich mag keinen Käse',\n",
              "     'phrase_audio': 'assets/audio/ai/ger/reciTOL2fmbj9noVi-ger.mp3',\n",
              "     'phrase_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1697635328/langdeck/assets/audio/ai/ger/reciTOL2fmbj9noVi-ger.mp3',\n",
              "     'phrase_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1697634759/langdeck/assets/audio/ai/fre/reciTOL2fmbj9noVi-fre.mp3',\n",
              "     'phrase_related_story_tr': 'Frühstück (Fortsetzung)',\n",
              "     'phrase_notes': '',\n",
              "     'phrase_notes_2': '',\n",
              "     'phrase_notes_translation': '',\n",
              "     'phrase_notes_2_translation': '',\n",
              "     'words': [{'word_language': 'ger',\n",
              "       'word': 'Fromage',\n",
              "       'word_rec_id': 'recoUyEv4BuTkl2Jy',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'recoUyEv4BuTkl2Jy-ger',\n",
              "       'word_translation': 'Käse',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/recoUyEv4BuTkl2Jy-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679470/langdeck/assets/audio/ai/ger/recoUyEv4BuTkl2Jy-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679458/langdeck/assets/audio/ai/fre/recoUyEv4BuTkl2Jy-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': 'Le fromage est avant tout une fermentation du lait activée par des bactéries lactiques. Il en existe des centaines de types à travers le monde et la France en compte au moins 400. Il se consomme seul ou entre dans la préparation de nombreux plats.',\n",
              "       'word_nutri_notes': 'Le fromage est un aliment calorique en totalisant 338 Cal/100 g, essentiellement dû à ses lipides. C’est un bon fournisseur de protéines, de calcium, de phosphore, de vitamine A et de zinc.\\nLe fromage n’est pas à bannir de l’alimentation car il est riche de bienfaits sur le plan nutritionnel.',\n",
              "       'word_notes_translation': 'Käse ist vor allem eine durch Milchsäurebakterien aktivierte Fermentation von Milch. Weltweit gibt es Hunderte von Arten, in Frankreich gibt es mindestens 400. Man verzehrt sie allein oder verwendet sie für die Zubereitung vieler Gerichte.',\n",
              "       'word_nutri_notes_translation': 'Käse ist ein kalorienreiches Lebensmittel mit insgesamt 338 Kalorien pro 100 g, vor allem aufgrund seiner Lipide. Es ist ein guter Lieferant von Eiweiß, Kalzium, Phosphor, Vitamin A und Zink.\\nKäse sollte nicht vom Speiseplan verbannt werden, da er reich an ernährungsphysiologischen Vorteilen ist.',\n",
              "       'word_tr_rec_id': 'recoUyEv4BuTkl2Jy-ger',\n",
              "       'keywords': []}]},\n",
              "    {'phrase_language': 'ger',\n",
              "     'phrase_related_story': 'Le petit-déjeuner (suite)',\n",
              "     'phrase_related_story_rec_id': 'rec2XfSwLVFBBiHj7',\n",
              "     'phrase_paragraph': '5',\n",
              "     'phrase_position': '5',\n",
              "     'phrase_rec_id': 'recK4R0maJbkoChIL',\n",
              "     'phrase': 'Tu veux un œuf ?',\n",
              "     'phrase_words': \"['Œuf']\",\n",
              "     'phrase_words_rec_id': \"['recoSeRIZS7t92XIR']\",\n",
              "     'phrase_words_tr': \"['Ei']\",\n",
              "     'phrase_words_tr_rec_id': \"['recoSeRIZS7t92XIR-ger']\",\n",
              "     'phrase_html': 'Tu veux un <span id=\"recoSeRIZS7t92XIR\">œuf</span> ?',\n",
              "     'phrase_html_rec_id': 'Tu veux un <kw>recoSeRIZS7t92XIR<kw> ?',\n",
              "     'phrase_html_kw': 'Tu veux un <kw>œuf<kw> ?',\n",
              "     'phrase_translation': 'Willst du ein Ei?',\n",
              "     'phrase_audio': 'assets/audio/ai/ger/recK4R0maJbkoChIL-ger.mp3',\n",
              "     'phrase_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1697634764/langdeck/assets/audio/ai/ger/recK4R0maJbkoChIL-ger.mp3',\n",
              "     'phrase_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1697634760/langdeck/assets/audio/ai/fre/recK4R0maJbkoChIL-fre.mp3',\n",
              "     'phrase_related_story_tr': 'Frühstück (Fortsetzung)',\n",
              "     'phrase_notes': '',\n",
              "     'phrase_notes_2': '',\n",
              "     'phrase_notes_translation': '',\n",
              "     'phrase_notes_2_translation': '',\n",
              "     'words': [{'word_language': 'ger',\n",
              "       'word': 'Œuf',\n",
              "       'word_rec_id': 'recoSeRIZS7t92XIR',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'recoSeRIZS7t92XIR-ger',\n",
              "       'word_translation': 'Ei',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/recoSeRIZS7t92XIR-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679474/langdeck/assets/audio/ai/ger/recoSeRIZS7t92XIR-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679462/langdeck/assets/audio/ai/fre/recoSeRIZS7t92XIR-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': 'Consommé partout dans le monde depuis des millénaires, l’œuf est apprécié pour ses qualités nutritionnelles, notamment sa richesse en protéines, vitamines et oligo-éléments, sa facilité et diversité d’utilisation et son faible coût.',\n",
              "       'word_nutri_notes': 'L’œuf est peu calorique, avec 150 Kcal pour deux œufs, soit 7% de l’apport énergétique total recommandé chez une femme (2 000 Kcal/jour), ce qui en fait un aliment très apprécié dans les régimes amaigrissants.',\n",
              "       'word_notes_translation': 'Das Ei wird seit Jahrtausenden auf der ganzen Welt konsumiert und wird wegen seiner ernährungsphysiologischen Eigenschaften geschätzt, insbesondere seines Reichtums an Proteinen, Vitaminen und Spurenelementen, seiner einfachen und vielfältigen Verwendung sowie seiner geringen Kosten.',\n",
              "       'word_nutri_notes_translation': 'Das Ei ist kalorienarm, mit 150 Kcal für zwei Eier oder 7 % der empfohlenen Gesamtenergiezufuhr einer Frau (2.000 Kcal/Tag), was es zu einem sehr beliebten Lebensmittel bei Diäten zur Gewichtsabnahme macht.',\n",
              "       'word_tr_rec_id': 'recoSeRIZS7t92XIR-ger',\n",
              "       'keywords': []}]},\n",
              "    {'phrase_language': 'ger',\n",
              "     'phrase_related_story': 'Le petit-déjeuner (suite)',\n",
              "     'phrase_related_story_rec_id': 'rec2XfSwLVFBBiHj7',\n",
              "     'phrase_paragraph': '6',\n",
              "     'phrase_position': '6',\n",
              "     'phrase_rec_id': 'rec1FT308NgPpEpoo',\n",
              "     'phrase': \"S'il te plait, je veux bien un œuf au plat\",\n",
              "     'phrase_words': \"['Œuf au plat']\",\n",
              "     'phrase_words_rec_id': \"['recT4pYfb6prJ2atR']\",\n",
              "     'phrase_words_tr': \"['Spiegelei']\",\n",
              "     'phrase_words_tr_rec_id': \"['recT4pYfb6prJ2atR-ger']\",\n",
              "     'phrase_html': 'S\\'il te plait, je veux bien un <span id=\"recT4pYfb6prJ2atR\">œuf au plat</span>',\n",
              "     'phrase_html_rec_id': \"S'il te plait, je veux bien un <kw>recT4pYfb6prJ2atR<kw>\",\n",
              "     'phrase_html_kw': \"S'il te plait, je veux bien un <kw>œuf au plat<kw>\",\n",
              "     'phrase_translation': 'Bitte, ich hätte gerne ein Spiegelei',\n",
              "     'phrase_audio': 'assets/audio/ai/ger/rec1FT308NgPpEpoo-ger.mp3',\n",
              "     'phrase_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1697635329/langdeck/assets/audio/ai/ger/rec1FT308NgPpEpoo-ger.mp3',\n",
              "     'phrase_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1697634761/langdeck/assets/audio/ai/fre/rec1FT308NgPpEpoo-fre.mp3',\n",
              "     'phrase_related_story_tr': 'Frühstück (Fortsetzung)',\n",
              "     'phrase_notes': '',\n",
              "     'phrase_notes_2': '',\n",
              "     'phrase_notes_translation': '',\n",
              "     'phrase_notes_2_translation': '',\n",
              "     'words': [{'word_language': 'ger',\n",
              "       'word': 'Œuf au plat',\n",
              "       'word_rec_id': 'recT4pYfb6prJ2atR',\n",
              "       'order': 2,\n",
              "       'word_type': 'Expression',\n",
              "       'word_translation_id': 'recT4pYfb6prJ2atR-ger',\n",
              "       'word_translation': 'Spiegelei',\n",
              "       'word_lemmas': \"['Œuf']\",\n",
              "       'word_lemmas_rec_id': \"['recoSeRIZS7t92XIR']\",\n",
              "       'word_audio': 'assets/audio/ai/ger/recT4pYfb6prJ2atR-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1697635180/langdeck/assets/audio/ai/ger/recT4pYfb6prJ2atR-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1697635179/langdeck/assets/audio/ai/fre/recT4pYfb6prJ2atR-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': \"['recoSeRIZS7t92XIR-ger']\",\n",
              "       'word_lemmas_tr': \"['Ei']\",\n",
              "       'word_notes': '',\n",
              "       'word_nutri_notes': '',\n",
              "       'word_notes_translation': '',\n",
              "       'word_nutri_notes_translation': '',\n",
              "       'word_tr_rec_id': 'recT4pYfb6prJ2atR-ger',\n",
              "       'keywords': [{'word_language': 'ger',\n",
              "         'word': 'Œuf',\n",
              "         'word_rec_id': 'recoSeRIZS7t92XIR',\n",
              "         'order': 1,\n",
              "         'word_type': 'Lemma',\n",
              "         'word_translation_id': 'recoSeRIZS7t92XIR-ger',\n",
              "         'word_translation': 'Ei',\n",
              "         'word_lemmas': '',\n",
              "         'word_lemmas_rec_id': '',\n",
              "         'word_audio': 'assets/audio/ai/ger/recoSeRIZS7t92XIR-ger.mp3',\n",
              "         'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679474/langdeck/assets/audio/ai/ger/recoSeRIZS7t92XIR-ger.mp3',\n",
              "         'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679462/langdeck/assets/audio/ai/fre/recoSeRIZS7t92XIR-fre.mp3',\n",
              "         'word_lemmas_tr_rec_id': '',\n",
              "         'word_lemmas_tr': '',\n",
              "         'word_notes': 'Consommé partout dans le monde depuis des millénaires, l’œuf est apprécié pour ses qualités nutritionnelles, notamment sa richesse en protéines, vitamines et oligo-éléments, sa facilité et diversité d’utilisation et son faible coût.',\n",
              "         'word_nutri_notes': 'L’œuf est peu calorique, avec 150 Kcal pour deux œufs, soit 7% de l’apport énergétique total recommandé chez une femme (2 000 Kcal/jour), ce qui en fait un aliment très apprécié dans les régimes amaigrissants.',\n",
              "         'word_notes_translation': 'Das Ei wird seit Jahrtausenden auf der ganzen Welt konsumiert und wird wegen seiner ernährungsphysiologischen Eigenschaften geschätzt, insbesondere seines Reichtums an Proteinen, Vitaminen und Spurenelementen, seiner einfachen und vielfältigen Verwendung sowie seiner geringen Kosten.',\n",
              "         'word_nutri_notes_translation': 'Das Ei ist kalorienarm, mit 150 Kcal für zwei Eier oder 7 % der empfohlenen Gesamtenergiezufuhr einer Frau (2.000 Kcal/Tag), was es zu einem sehr beliebten Lebensmittel bei Diäten zur Gewichtsabnahme macht.',\n",
              "         'keyword': 'recoSeRIZS7t92XIR'}]}]},\n",
              "    {'phrase_language': 'ger',\n",
              "     'phrase_related_story': 'Le petit-déjeuner (suite)',\n",
              "     'phrase_related_story_rec_id': 'rec2XfSwLVFBBiHj7',\n",
              "     'phrase_paragraph': '7',\n",
              "     'phrase_position': '7',\n",
              "     'phrase_rec_id': 'recYyHnx1RW6rkDQH',\n",
              "     'phrase': 'Tu veux de la bière ?',\n",
              "     'phrase_words': \"['Bière']\",\n",
              "     'phrase_words_rec_id': \"['recrjtZ5EXbIiGEMX']\",\n",
              "     'phrase_words_tr': \"['Bier']\",\n",
              "     'phrase_words_tr_rec_id': \"['recrjtZ5EXbIiGEMX-ger']\",\n",
              "     'phrase_html': 'Tu veux de la <span id=\"recrjtZ5EXbIiGEMX\">bière</span> ?',\n",
              "     'phrase_html_rec_id': 'Tu veux de la <kw>recrjtZ5EXbIiGEMX<kw> ?',\n",
              "     'phrase_html_kw': 'Tu veux de la <kw>bière<kw> ?',\n",
              "     'phrase_translation': 'Willst du etwas Bier?',\n",
              "     'phrase_audio': 'assets/audio/ai/ger/recYyHnx1RW6rkDQH-ger.mp3',\n",
              "     'phrase_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696947313/langdeck/assets/audio/ai/ger/recYyHnx1RW6rkDQH-ger.mp3',\n",
              "     'phrase_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696947297/langdeck/assets/audio/ai/fre/recYyHnx1RW6rkDQH-fre.mp3',\n",
              "     'phrase_related_story_tr': 'Frühstück (Fortsetzung)',\n",
              "     'phrase_notes': '',\n",
              "     'phrase_notes_2': '',\n",
              "     'phrase_notes_translation': '',\n",
              "     'phrase_notes_2_translation': '',\n",
              "     'words': [{'word_language': 'ger',\n",
              "       'word': 'Bière',\n",
              "       'word_rec_id': 'recrjtZ5EXbIiGEMX',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'recrjtZ5EXbIiGEMX-ger',\n",
              "       'word_translation': 'Bier',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/recrjtZ5EXbIiGEMX-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679467/langdeck/assets/audio/ai/ger/recrjtZ5EXbIiGEMX-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679455/langdeck/assets/audio/ai/fre/recrjtZ5EXbIiGEMX-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': '',\n",
              "       'word_nutri_notes': '',\n",
              "       'word_notes_translation': '',\n",
              "       'word_nutri_notes_translation': '',\n",
              "       'word_tr_rec_id': 'recrjtZ5EXbIiGEMX-ger',\n",
              "       'keywords': []}]},\n",
              "    {'phrase_language': 'ger',\n",
              "     'phrase_related_story': 'Le petit-déjeuner (suite)',\n",
              "     'phrase_related_story_rec_id': 'rec2XfSwLVFBBiHj7',\n",
              "     'phrase_paragraph': '8',\n",
              "     'phrase_position': '8',\n",
              "     'phrase_rec_id': 'reckJNZKgpFLe91gG',\n",
              "     'phrase': 'Haha ! Non merci, pas de bière au petit-déjeuner',\n",
              "     'phrase_words': \"['Bière', 'Petit-déjeuner']\",\n",
              "     'phrase_words_rec_id': \"['recrjtZ5EXbIiGEMX', 'recrYaJMdw31vgPT5']\",\n",
              "     'phrase_words_tr': \"['Bier', 'Frühstück']\",\n",
              "     'phrase_words_tr_rec_id': \"['recrjtZ5EXbIiGEMX-ger', 'recrYaJMdw31vgPT5-ger']\",\n",
              "     'phrase_html': 'Haha ! Non merci, pas de <span id=\"recrjtZ5EXbIiGEMX\">bière</span> au <span id=\"recrYaJMdw31vgPT5\">petit-déjeuner</span>.',\n",
              "     'phrase_html_rec_id': 'Haha ! Non merci, pas de <kw>recrjtZ5EXbIiGEMX<kw> au <kw>recrYaJMdw31vgPT5<kw>.',\n",
              "     'phrase_html_kw': 'Haha ! Non merci, pas de <kw>bière<kw> au <kw>petit-déjeuner<kw>.',\n",
              "     'phrase_translation': 'Haha! Nein danke, kein Bier zum Frühstück',\n",
              "     'phrase_audio': 'assets/audio/ai/ger/reckJNZKgpFLe91gG-ger.mp3',\n",
              "     'phrase_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696947313/langdeck/assets/audio/ai/ger/reckJNZKgpFLe91gG-ger.mp3',\n",
              "     'phrase_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696947298/langdeck/assets/audio/ai/fre/reckJNZKgpFLe91gG-fre.mp3',\n",
              "     'phrase_related_story_tr': 'Frühstück (Fortsetzung)',\n",
              "     'phrase_notes': '',\n",
              "     'phrase_notes_2': '',\n",
              "     'phrase_notes_translation': '',\n",
              "     'phrase_notes_2_translation': '',\n",
              "     'words': [{'word_language': 'ger',\n",
              "       'word': 'Bière',\n",
              "       'word_rec_id': 'recrjtZ5EXbIiGEMX',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'recrjtZ5EXbIiGEMX-ger',\n",
              "       'word_translation': 'Bier',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/recrjtZ5EXbIiGEMX-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679467/langdeck/assets/audio/ai/ger/recrjtZ5EXbIiGEMX-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679455/langdeck/assets/audio/ai/fre/recrjtZ5EXbIiGEMX-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': '',\n",
              "       'word_nutri_notes': '',\n",
              "       'word_notes_translation': '',\n",
              "       'word_nutri_notes_translation': '',\n",
              "       'word_tr_rec_id': 'recrjtZ5EXbIiGEMX-ger',\n",
              "       'keywords': []},\n",
              "      {'word_language': 'ger',\n",
              "       'word': 'Petit-déjeuner',\n",
              "       'word_rec_id': 'recrYaJMdw31vgPT5',\n",
              "       'order': 1,\n",
              "       'word_type': 'Lemma',\n",
              "       'word_translation_id': 'recrYaJMdw31vgPT5-ger',\n",
              "       'word_translation': 'Frühstück',\n",
              "       'word_lemmas': '',\n",
              "       'word_lemmas_rec_id': '',\n",
              "       'word_audio': 'assets/audio/ai/ger/recrYaJMdw31vgPT5-ger.mp3',\n",
              "       'word_audio_url': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679475/langdeck/assets/audio/ai/ger/recrYaJMdw31vgPT5-ger.mp3',\n",
              "       'word_audio_url_fr': 'http://res.cloudinary.com/dhc7ovnwk/video/upload/v1696679464/langdeck/assets/audio/ai/fre/recrYaJMdw31vgPT5-fre.mp3',\n",
              "       'word_lemmas_tr_rec_id': '',\n",
              "       'word_lemmas_tr': '',\n",
              "       'word_notes': '',\n",
              "       'word_nutri_notes': '',\n",
              "       'word_notes_translation': '',\n",
              "       'word_nutri_notes_translation': '',\n",
              "       'word_tr_rec_id': 'recrYaJMdw31vgPT5-ger',\n",
              "       'keywords': []}]}]}]}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sauvegarde au format JSON"
      ],
      "metadata": {
        "id": "Rs8wxEqT97rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('saynetes.txt', 'w') as f:\n",
        "  json.dump(vk_lang, f, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "H4R4TUxWGrVs"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RNkqYnqJzVzL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}